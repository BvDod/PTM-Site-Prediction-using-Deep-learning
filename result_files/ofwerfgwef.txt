{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'learning_rate': 0.004354958527237924,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2582102064,
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.813922644366503}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.692
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
Early stopping applied (best metric=0.48909512162208557)
Finished Training
Total time taken: 29.820571422576904
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.692
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.692
[76,    11] loss: 0.693
[77,    11] loss: 0.693
[78,    11] loss: 0.692
[79,    11] loss: 0.692
[80,    11] loss: 0.693
[81,    11] loss: 0.693
[82,    11] loss: 0.693
[83,    11] loss: 0.693
[84,    11] loss: 0.693
[85,    11] loss: 0.693
Early stopping applied (best metric=0.4890283942222595)
Finished Training
Total time taken: 35.40383005142212
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.693
[76,    11] loss: 0.693
[77,    11] loss: 0.693
[78,    11] loss: 0.693
[79,    11] loss: 0.693
[80,    11] loss: 0.693
[81,    11] loss: 0.693
[82,    11] loss: 0.693
[83,    11] loss: 0.693
[84,    11] loss: 0.693
[85,    11] loss: 0.693
[86,    11] loss: 0.693
[87,    11] loss: 0.693
[88,    11] loss: 0.693
[89,    11] loss: 0.693
[90,    11] loss: 0.693
[91,    11] loss: 0.693
[92,    11] loss: 0.693
[93,    11] loss: 0.693
[94,    11] loss: 0.693
[95,    11] loss: 0.693
[96,    11] loss: 0.693
[97,    11] loss: 0.693
[98,    11] loss: 0.693
[99,    11] loss: 0.693
[100,    11] loss: 0.693
[101,    11] loss: 0.693
[102,    11] loss: 0.693
[103,    11] loss: 0.693
[104,    11] loss: 0.693
[105,    11] loss: 0.693
[106,    11] loss: 0.693
[107,    11] loss: 0.693
[108,    11] loss: 0.693
[109,    11] loss: 0.693
[110,    11] loss: 0.693
[111,    11] loss: 0.693
[112,    11] loss: 0.693
Early stopping applied (best metric=0.4887930750846863)
Finished Training
Total time taken: 48.8140823841095
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.693
[76,    11] loss: 0.693
[77,    11] loss: 0.693
[78,    11] loss: 0.693
[79,    11] loss: 0.693
[80,    11] loss: 0.693
[81,    11] loss: 0.693
[82,    11] loss: 0.693
[83,    11] loss: 0.693
[84,    11] loss: 0.693
Early stopping applied (best metric=0.4885656237602234)
Finished Training
Total time taken: 38.35899639129639
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
Early stopping applied (best metric=0.48883724212646484)
Finished Training
Total time taken: 22.13633918762207
{'Sumoylation Validation Accuracy': 0.20040949974185485, 'Sumoylation Validation Sensitivity': 0.9685270786965702, 'Sumoylation Validation Specificity': 0.07747826325461477, 'Sumoylation Validation Precision': 0.14385640537163308, 'Sumoylation AUC ROC': 0.5819272868193442, 'Sumoylation AUC PR': 0.4327898288115712, 'Sumoylation MCC': 0.06162485891980152, 'Sumoylation F1': 0.2505038680323538, 'Validation Loss (Sumoylation)': 0.4888638913631439, 'Validation Loss (total)': 0.4888638913631439, 'TimeToTrain': 34.9067638874054}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009950156514951448,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 815410192,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 10.964630371314666}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.693
[10,    11] loss: 0.692
[11,    11] loss: 0.692
[12,    11] loss: 0.692
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.692
[53,    11] loss: 0.692
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.692
[61,    11] loss: 0.692
[62,    11] loss: 0.692
[63,    11] loss: 0.692
Early stopping applied (best metric=0.4885450601577759)
Finished Training
Total time taken: 27.756125688552856
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.692
[15,    11] loss: 0.693
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.692
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.692
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.692
[52,    11] loss: 0.692
[53,    11] loss: 0.692
[54,    11] loss: 0.692
[55,    11] loss: 0.692
[56,    11] loss: 0.692
[57,    11] loss: 0.692
[58,    11] loss: 0.692
[59,    11] loss: 0.692
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.692
[63,    11] loss: 0.693
[64,    11] loss: 0.692
[65,    11] loss: 0.692
[66,    11] loss: 0.692
[67,    11] loss: 0.692
[68,    11] loss: 0.692
[69,    11] loss: 0.692
[70,    11] loss: 0.693
[71,    11] loss: 0.692
[72,    11] loss: 0.693
[73,    11] loss: 0.692
[74,    11] loss: 0.692
[75,    11] loss: 0.692
[76,    11] loss: 0.692
[77,    11] loss: 0.693
[78,    11] loss: 0.692
[79,    11] loss: 0.693
[80,    11] loss: 0.692
[81,    11] loss: 0.692
[82,    11] loss: 0.692
[83,    11] loss: 0.692
[84,    11] loss: 0.692
[85,    11] loss: 0.692
[86,    11] loss: 0.692
[87,    11] loss: 0.692
[88,    11] loss: 0.692
[89,    11] loss: 0.692
[90,    11] loss: 0.692
[91,    11] loss: 0.692
[92,    11] loss: 0.692
[93,    11] loss: 0.693
[94,    11] loss: 0.693
[95,    11] loss: 0.693
[96,    11] loss: 0.693
[97,    11] loss: 0.693
[98,    11] loss: 0.693
[99,    11] loss: 0.692
[100,    11] loss: 0.693
[101,    11] loss: 0.693
[102,    11] loss: 0.693
Early stopping applied (best metric=0.4883684515953064)
Finished Training
Total time taken: 45.54313898086548
[1,     1] loss: 0.697
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.692
[11,    11] loss: 0.692
[12,    11] loss: 0.692
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.693
[19,    11] loss: 0.692
[20,    11] loss: 0.693
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.693
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.692
[41,    11] loss: 0.692
[42,    11] loss: 0.692
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.692
[54,    11] loss: 0.692
[55,    11] loss: 0.692
[56,    11] loss: 0.692
[57,    11] loss: 0.692
[58,    11] loss: 0.692
[59,    11] loss: 0.692
[60,    11] loss: 0.692
[61,    11] loss: 0.692
[62,    11] loss: 0.692
[63,    11] loss: 0.692
[64,    11] loss: 0.692
[65,    11] loss: 0.692
[66,    11] loss: 0.692
[67,    11] loss: 0.692
[68,    11] loss: 0.692
[69,    11] loss: 0.692
[70,    11] loss: 0.692
[71,    11] loss: 0.692
[72,    11] loss: 0.692
[73,    11] loss: 0.692
[74,    11] loss: 0.692
[75,    11] loss: 0.692
[76,    11] loss: 0.692
[77,    11] loss: 0.692
[78,    11] loss: 0.692
[79,    11] loss: 0.692
[80,    11] loss: 0.692
[81,    11] loss: 0.692
[82,    11] loss: 0.692
[83,    11] loss: 0.692
Early stopping applied (best metric=0.4883682131767273)
Finished Training
Total time taken: 37.1565158367157
[1,     1] loss: 0.689
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.692
[12,    11] loss: 0.692
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.693
[23,    11] loss: 0.692
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.692
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
Early stopping applied (best metric=0.48333820700645447)
Finished Training
Total time taken: 27.42987608909607
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.691
[10,    11] loss: 0.691
[11,    11] loss: 0.691
[12,    11] loss: 0.691
[13,    11] loss: 0.692
[14,    11] loss: 0.691
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.693
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.693
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.693
[42,    11] loss: 0.692
[43,    11] loss: 0.692
[44,    11] loss: 0.692
[45,    11] loss: 0.692
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.692
Early stopping applied (best metric=0.4842089116573334)
Finished Training
Total time taken: 20.553680896759033
{'Sumoylation Validation Accuracy': 0.17716473284240464, 'Sumoylation Validation Sensitivity': 0.9802554737582986, 'Sumoylation Validation Specificity': 0.04863819633012425, 'Sumoylation Validation Precision': 0.1416749955323309, 'Sumoylation AUC ROC': 0.5559601010077357, 'Sumoylation AUC PR': 0.41016942400313167, 'Sumoylation MCC': 0.037993702419041514, 'Sumoylation F1': 0.24752968589236363, 'Validation Loss (Sumoylation)': 0.4865657687187195, 'Validation Loss (total)': 0.4865657687187195, 'TimeToTrain': 31.68786749839783}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0040341579383632205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 517716754,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 21.72648581705655}
[1,     1] loss: 0.692
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
Early stopping applied (best metric=0.4886830747127533)
Finished Training
Total time taken: 21.2314510345459
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.693
[76,    11] loss: 0.693
[77,    11] loss: 0.692
[78,    11] loss: 0.693
[79,    11] loss: 0.693
[80,    11] loss: 0.692
Early stopping applied (best metric=0.48930636048316956)
Finished Training
Total time taken: 32.28783440589905
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
Early stopping applied (best metric=0.4875713884830475)
Finished Training
Total time taken: 22.679600715637207
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.693
[76,    11] loss: 0.693
[77,    11] loss: 0.693
[78,    11] loss: 0.693
[79,    11] loss: 0.693
[80,    11] loss: 0.693
[81,    11] loss: 0.693
[82,    11] loss: 0.693
[83,    11] loss: 0.693
[84,    11] loss: 0.693
[85,    11] loss: 0.693
[86,    11] loss: 0.693
[87,    11] loss: 0.693
[88,    11] loss: 0.693
[89,    11] loss: 0.693
[90,    11] loss: 0.693
[91,    11] loss: 0.693
[92,    11] loss: 0.693
[93,    11] loss: 0.693
[94,    11] loss: 0.693
[95,    11] loss: 0.693
[96,    11] loss: 0.693
[97,    11] loss: 0.693
Early stopping applied (best metric=0.4890033006668091)
Finished Training
Total time taken: 40.47829723358154
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
[28,    11] loss: 0.693
[29,    11] loss: 0.693
[30,    11] loss: 0.693
[31,    11] loss: 0.693
[32,    11] loss: 0.693
[33,    11] loss: 0.693
[34,    11] loss: 0.693
[35,    11] loss: 0.693
[36,    11] loss: 0.693
[37,    11] loss: 0.693
[38,    11] loss: 0.693
[39,    11] loss: 0.693
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.693
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
[54,    11] loss: 0.693
[55,    11] loss: 0.693
[56,    11] loss: 0.693
[57,    11] loss: 0.693
[58,    11] loss: 0.693
[59,    11] loss: 0.693
[60,    11] loss: 0.693
[61,    11] loss: 0.693
[62,    11] loss: 0.693
[63,    11] loss: 0.693
[64,    11] loss: 0.693
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
[68,    11] loss: 0.693
[69,    11] loss: 0.693
[70,    11] loss: 0.693
[71,    11] loss: 0.693
[72,    11] loss: 0.693
[73,    11] loss: 0.693
[74,    11] loss: 0.693
[75,    11] loss: 0.693
[76,    11] loss: 0.693
[77,    11] loss: 0.693
[78,    11] loss: 0.693
[79,    11] loss: 0.693
[80,    11] loss: 0.693
[81,    11] loss: 0.693
[82,    11] loss: 0.693
[83,    11] loss: 0.693
[84,    11] loss: 0.693
[85,    11] loss: 0.693
[86,    11] loss: 0.693
[87,    11] loss: 0.693
[88,    11] loss: 0.693
[89,    11] loss: 0.693
[90,    11] loss: 0.693
[91,    11] loss: 0.693
[92,    11] loss: 0.693
[93,    11] loss: 0.693
[94,    11] loss: 0.693
[95,    11] loss: 0.693
[96,    11] loss: 0.693
[97,    11] loss: 0.693
[98,    11] loss: 0.693
[99,    11] loss: 0.693
[100,    11] loss: 0.693
[101,    11] loss: 0.693
[102,    11] loss: 0.693
[103,    11] loss: 0.693
[104,    11] loss: 0.693
[105,    11] loss: 0.693
[106,    11] loss: 0.693
[107,    11] loss: 0.693
[108,    11] loss: 0.693
[109,    11] loss: 0.693
[110,    11] loss: 0.693
[111,    11] loss: 0.693
[112,    11] loss: 0.693
[113,    11] loss: 0.693
Early stopping applied (best metric=0.488579124212265)
Finished Training
Total time taken: 44.525721073150635
{'Sumoylation Validation Accuracy': 0.1886162513699809, 'Sumoylation Validation Sensitivity': 0.9765522456200422, 'Sumoylation Validation Specificity': 0.06251461763746796, 'Sumoylation Validation Precision': 0.14296695508233642, 'Sumoylation AUC ROC': 0.5812920406011977, 'Sumoylation AUC PR': 0.43047621467598335, 'Sumoylation MCC': 0.052261973357077066, 'Sumoylation F1': 0.24939475687300125, 'Validation Loss (Sumoylation)': 0.4886286497116089, 'Validation Loss (total)': 0.4886286497116089, 'TimeToTrain': 32.24058089256287}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005846885755444568,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2428972504,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 9.813221652565984}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.691
[11,    11] loss: 0.692
[12,    11] loss: 0.691
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.693
[24,    11] loss: 0.692
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035552406162590094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3104703072,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.1417171865766136}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.690
[5,    11] loss: 0.690
[6,    11] loss: 0.691
[7,    11] loss: 0.691
[8,    11] loss: 0.689
[9,    11] loss: 0.689
[10,    11] loss: 0.689
[11,    11] loss: 0.689
[12,    11] loss: 0.684
[13,    11] loss: 0.669
[14,    11] loss: 0.656
[15,    11] loss: 0.640
[16,    11] loss: 0.624
[17,    11] loss: 0.615
[18,    11] loss: 0.615
[19,    11] loss: 0.614
[20,    11] loss: 0.602
[21,    11] loss: 0.592
[22,    11] loss: 0.597
[23,    11] loss: 0.598
[24,    11] loss: 0.590
[25,    11] loss: 0.583
[26,    11] loss: 0.591
[27,    11] loss: 0.598
[28,    11] loss: 0.591
[29,    11] loss: 0.580
[30,    11] loss: 0.579
[31,    11] loss: 0.582
[32,    11] loss: 0.572
[33,    11] loss: 0.585
[34,    11] loss: 0.576
[35,    11] loss: 0.579
[36,    11] loss: 0.572
[37,    11] loss: 0.575
[38,    11] loss: 0.568
[39,    11] loss: 0.574
[40,    11] loss: 0.566
[41,    11] loss: 0.571
[42,    11] loss: 0.573
[43,    11] loss: 0.584
[44,    11] loss: 0.565
[45,    11] loss: 0.575
[46,    11] loss: 0.575
[47,    11] loss: 0.572
[48,    11] loss: 0.574
[49,    11] loss: 0.571
[50,    11] loss: 0.562
[51,    11] loss: 0.573
[52,    11] loss: 0.570
[53,    11] loss: 0.576
[54,    11] loss: 0.561
[55,    11] loss: 0.557
[56,    11] loss: 0.558
[57,    11] loss: 0.574
[58,    11] loss: 0.562
[59,    11] loss: 0.570
[60,    11] loss: 0.564
[61,    11] loss: 0.568
[62,    11] loss: 0.577
[63,    11] loss: 0.588
[64,    11] loss: 0.578
[65,    11] loss: 0.582
[66,    11] loss: 0.567
[67,    11] loss: 0.554
[68,    11] loss: 0.562
[69,    11] loss: 0.573
[70,    11] loss: 0.575
[71,    11] loss: 0.561
[72,    11] loss: 0.549
[73,    11] loss: 0.564
[74,    11] loss: 0.578
[75,    11] loss: 0.565
[76,    11] loss: 0.565
[77,    11] loss: 0.566
[78,    11] loss: 0.572
[79,    11] loss: 0.570
[80,    11] loss: 0.579
[81,    11] loss: 0.551
[82,    11] loss: 0.584
[83,    11] loss: 0.566
[84,    11] loss: 0.564
[85,    11] loss: 0.572
[86,    11] loss: 0.558
[87,    11] loss: 0.559
[88,    11] loss: 0.567
[89,    11] loss: 0.553
[90,    11] loss: 0.559
[91,    11] loss: 0.569
[92,    11] loss: 0.571
[93,    11] loss: 0.577
[94,    11] loss: 0.571
[95,    11] loss: 0.551
[96,    11] loss: 0.556
[97,    11] loss: 0.551
[98,    11] loss: 0.564
[99,    11] loss: 0.555
[100,    11] loss: 0.560
[101,    11] loss: 0.554
[102,    11] loss: 0.555
[103,    11] loss: 0.563
[104,    11] loss: 0.555
[105,    11] loss: 0.561
[106,    11] loss: 0.558
[107,    11] loss: 0.566
[108,    11] loss: 0.576
[109,    11] loss: 0.560
[110,    11] loss: 0.561
[111,    11] loss: 0.555
[112,    11] loss: 0.571
[113,    11] loss: 0.570
[114,    11] loss: 0.555
[115,    11] loss: 0.558
[116,    11] loss: 0.567
[117,    11] loss: 0.564
[118,    11] loss: 0.567
[119,    11] loss: 0.551
[120,    11] loss: 0.568
[121,    11] loss: 0.552
[122,    11] loss: 0.571
Early stopping applied (best metric=0.35778236389160156)
Finished Training
Total time taken: 48.36692523956299
[1,     1] loss: 0.694
[2,    11] loss: 0.692
[3,    11] loss: 0.691
[4,    11] loss: 0.691
[5,    11] loss: 0.691
[6,    11] loss: 0.689
[7,    11] loss: 0.690
[8,    11] loss: 0.690
[9,    11] loss: 0.688
[10,    11] loss: 0.689
[11,    11] loss: 0.688
[12,    11] loss: 0.688
[13,    11] loss: 0.688
[14,    11] loss: 0.685
[15,    11] loss: 0.676
[16,    11] loss: 0.668
[17,    11] loss: 0.663
[18,    11] loss: 0.650
[19,    11] loss: 0.621
[20,    11] loss: 0.618
[21,    11] loss: 0.611
[22,    11] loss: 0.606
[23,    11] loss: 0.606
[24,    11] loss: 0.604
[25,    11] loss: 0.603
[26,    11] loss: 0.614
[27,    11] loss: 0.595
[28,    11] loss: 0.599
[29,    11] loss: 0.594
[30,    11] loss: 0.581
[31,    11] loss: 0.583
[32,    11] loss: 0.585
[33,    11] loss: 0.581
[34,    11] loss: 0.567
[35,    11] loss: 0.590
[36,    11] loss: 0.582
[37,    11] loss: 0.568
[38,    11] loss: 0.592
[39,    11] loss: 0.580
[40,    11] loss: 0.582
[41,    11] loss: 0.577
[42,    11] loss: 0.575
[43,    11] loss: 0.579
[44,    11] loss: 0.578
[45,    11] loss: 0.582
[46,    11] loss: 0.569
[47,    11] loss: 0.574
[48,    11] loss: 0.587
[49,    11] loss: 0.573
[50,    11] loss: 0.576
[51,    11] loss: 0.573
[52,    11] loss: 0.584
[53,    11] loss: 0.575
[54,    11] loss: 0.589
[55,    11] loss: 0.585
[56,    11] loss: 0.575
[57,    11] loss: 0.563
[58,    11] loss: 0.569
[59,    11] loss: 0.570
[60,    11] loss: 0.574
[61,    11] loss: 0.583
[62,    11] loss: 0.580
[63,    11] loss: 0.561
[64,    11] loss: 0.565
[65,    11] loss: 0.578
[66,    11] loss: 0.579
[67,    11] loss: 0.558
[68,    11] loss: 0.565
[69,    11] loss: 0.577
[70,    11] loss: 0.583
[71,    11] loss: 0.568
[72,    11] loss: 0.568
[73,    11] loss: 0.565
[74,    11] loss: 0.569
[75,    11] loss: 0.583
[76,    11] loss: 0.566
[77,    11] loss: 0.566
[78,    11] loss: 0.569
[79,    11] loss: 0.562
[80,    11] loss: 0.567
[81,    11] loss: 0.557
[82,    11] loss: 0.552
[83,    11] loss: 0.563
[84,    11] loss: 0.569
[85,    11] loss: 0.561
[86,    11] loss: 0.560
[87,    11] loss: 0.558
[88,    11] loss: 0.568
[89,    11] loss: 0.552
[90,    11] loss: 0.566
[91,    11] loss: 0.566
[92,    11] loss: 0.557
[93,    11] loss: 0.560
[94,    11] loss: 0.556
[95,    11] loss: 0.565
[96,    11] loss: 0.573
[97,    11] loss: 0.568
[98,    11] loss: 0.560
[99,    11] loss: 0.565
[100,    11] loss: 0.555
[101,    11] loss: 0.567
[102,    11] loss: 0.553
[103,    11] loss: 0.564
[104,    11] loss: 0.558
[105,    11] loss: 0.554
[106,    11] loss: 0.554
[107,    11] loss: 0.559
[108,    11] loss: 0.566
[109,    11] loss: 0.549
[110,    11] loss: 0.563
[111,    11] loss: 0.574
[112,    11] loss: 0.557
[113,    11] loss: 0.556
[114,    11] loss: 0.573
[115,    11] loss: 0.566
[116,    11] loss: 0.559
[117,    11] loss: 0.567
[118,    11] loss: 0.556
[119,    11] loss: 0.554
[120,    11] loss: 0.567
[121,    11] loss: 0.558
[122,    11] loss: 0.573
[123,    11] loss: 0.570
[124,    11] loss: 0.586
[125,    11] loss: 0.570
[126,    11] loss: 0.577
[127,    11] loss: 0.548
[128,    11] loss: 0.554
[129,    11] loss: 0.551
[130,    11] loss: 0.561
[131,    11] loss: 0.563
[132,    11] loss: 0.563
[133,    11] loss: 0.570
[134,    11] loss: 0.552
[135,    11] loss: 0.559
[136,    11] loss: 0.564
[137,    11] loss: 0.554
[138,    11] loss: 0.564
[139,    11] loss: 0.560
[140,    11] loss: 0.553
[141,    11] loss: 0.558
[142,    11] loss: 0.572
[143,    11] loss: 0.563
[144,    11] loss: 0.559
[145,    11] loss: 0.559
[146,    11] loss: 0.567
[147,    11] loss: 0.555
[148,    11] loss: 0.560
[149,    11] loss: 0.556
[150,    11] loss: 0.566
[151,    11] loss: 0.567
[152,    11] loss: 0.555
[153,    11] loss: 0.558
[154,    11] loss: 0.561
[155,    11] loss: 0.566
[156,    11] loss: 0.565
[157,    11] loss: 0.555
[158,    11] loss: 0.556
[159,    11] loss: 0.570
[160,    11] loss: 0.561
Early stopping applied (best metric=0.36519619822502136)
Finished Training
Total time taken: 66.56122589111328
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.690
[5,    11] loss: 0.691
[6,    11] loss: 0.689
[7,    11] loss: 0.687
[8,    11] loss: 0.685
[9,    11] loss: 0.678
[10,    11] loss: 0.661
[11,    11] loss: 0.650
[12,    11] loss: 0.648
[13,    11] loss: 0.632
[14,    11] loss: 0.625
[15,    11] loss: 0.603
[16,    11] loss: 0.614
[17,    11] loss: 0.612
[18,    11] loss: 0.599
[19,    11] loss: 0.609
[20,    11] loss: 0.604
[21,    11] loss: 0.594
[22,    11] loss: 0.597
[23,    11] loss: 0.591
[24,    11] loss: 0.582
[25,    11] loss: 0.575
[26,    11] loss: 0.579
[27,    11] loss: 0.580
[28,    11] loss: 0.590
[29,    11] loss: 0.588
[30,    11] loss: 0.582
[31,    11] loss: 0.590
[32,    11] loss: 0.572
[33,    11] loss: 0.576
[34,    11] loss: 0.576
[35,    11] loss: 0.567
[36,    11] loss: 0.569
[37,    11] loss: 0.575
[38,    11] loss: 0.582
[39,    11] loss: 0.578
[40,    11] loss: 0.578
[41,    11] loss: 0.571
[42,    11] loss: 0.578
[43,    11] loss: 0.584
[44,    11] loss: 0.572
[45,    11] loss: 0.565
[46,    11] loss: 0.569
[47,    11] loss: 0.568
[48,    11] loss: 0.575
[49,    11] loss: 0.587
[50,    11] loss: 0.571
[51,    11] loss: 0.565
[52,    11] loss: 0.565
[53,    11] loss: 0.564
[54,    11] loss: 0.572
[55,    11] loss: 0.573
[56,    11] loss: 0.561
[57,    11] loss: 0.558
[58,    11] loss: 0.567
[59,    11] loss: 0.571
[60,    11] loss: 0.563
[61,    11] loss: 0.560
[62,    11] loss: 0.566
[63,    11] loss: 0.557
[64,    11] loss: 0.566
[65,    11] loss: 0.560
[66,    11] loss: 0.572
[67,    11] loss: 0.563
[68,    11] loss: 0.571
[69,    11] loss: 0.575
[70,    11] loss: 0.558
[71,    11] loss: 0.559
[72,    11] loss: 0.563
[73,    11] loss: 0.561
[74,    11] loss: 0.556
[75,    11] loss: 0.558
[76,    11] loss: 0.564
[77,    11] loss: 0.564
[78,    11] loss: 0.556
[79,    11] loss: 0.555
[80,    11] loss: 0.559
[81,    11] loss: 0.574
[82,    11] loss: 0.576
[83,    11] loss: 0.559
[84,    11] loss: 0.556
[85,    11] loss: 0.559
[86,    11] loss: 0.565
[87,    11] loss: 0.567
[88,    11] loss: 0.571
[89,    11] loss: 0.564
[90,    11] loss: 0.585
[91,    11] loss: 0.558
[92,    11] loss: 0.553
[93,    11] loss: 0.556
[94,    11] loss: 0.546
[95,    11] loss: 0.559
[96,    11] loss: 0.561
[97,    11] loss: 0.561
[98,    11] loss: 0.560
[99,    11] loss: 0.555
[100,    11] loss: 0.552
[101,    11] loss: 0.547
[102,    11] loss: 0.562
[103,    11] loss: 0.579
[104,    11] loss: 0.555
[105,    11] loss: 0.563
[106,    11] loss: 0.581
[107,    11] loss: 0.589
[108,    11] loss: 0.563
[109,    11] loss: 0.552
[110,    11] loss: 0.560
[111,    11] loss: 0.561
[112,    11] loss: 0.562
[113,    11] loss: 0.558
[114,    11] loss: 0.575
[115,    11] loss: 0.565
[116,    11] loss: 0.552
[117,    11] loss: 0.561
[118,    11] loss: 0.555
[119,    11] loss: 0.534
[120,    11] loss: 0.548
[121,    11] loss: 0.558
[122,    11] loss: 0.561
[123,    11] loss: 0.562
[124,    11] loss: 0.560
[125,    11] loss: 0.550
[126,    11] loss: 0.553
[127,    11] loss: 0.580
[128,    11] loss: 0.571
[129,    11] loss: 0.558
[130,    11] loss: 0.555
[131,    11] loss: 0.557
[132,    11] loss: 0.556
[133,    11] loss: 0.561
[134,    11] loss: 0.556
[135,    11] loss: 0.547
[136,    11] loss: 0.575
[137,    11] loss: 0.553
[138,    11] loss: 0.550
[139,    11] loss: 0.553
[140,    11] loss: 0.554
[141,    11] loss: 0.555
[142,    11] loss: 0.569
[143,    11] loss: 0.554
[144,    11] loss: 0.572
[145,    11] loss: 0.563
[146,    11] loss: 0.578
[147,    11] loss: 0.565
[148,    11] loss: 0.553
[149,    11] loss: 0.562
[150,    11] loss: 0.561
[151,    11] loss: 0.573
[152,    11] loss: 0.561
Early stopping applied (best metric=0.3683720827102661)
Finished Training
Total time taken: 67.78944206237793
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.691
[5,    11] loss: 0.692
[6,    11] loss: 0.691
[7,    11] loss: 0.690
[8,    11] loss: 0.688
[9,    11] loss: 0.688
[10,    11] loss: 0.687
[11,    11] loss: 0.687
[12,    11] loss: 0.687
[13,    11] loss: 0.675
[14,    11] loss: 0.659
[15,    11] loss: 0.645
[16,    11] loss: 0.644
[17,    11] loss: 0.614
[18,    11] loss: 0.612
[19,    11] loss: 0.622
[20,    11] loss: 0.613
[21,    11] loss: 0.596
[22,    11] loss: 0.599
[23,    11] loss: 0.592
[24,    11] loss: 0.610
[25,    11] loss: 0.594
[26,    11] loss: 0.584
[27,    11] loss: 0.579
[28,    11] loss: 0.577
[29,    11] loss: 0.589
[30,    11] loss: 0.587
[31,    11] loss: 0.572
[32,    11] loss: 0.571
[33,    11] loss: 0.568
[34,    11] loss: 0.562
[35,    11] loss: 0.584
[36,    11] loss: 0.583
[37,    11] loss: 0.574
[38,    11] loss: 0.570
[39,    11] loss: 0.570
[40,    11] loss: 0.572
[41,    11] loss: 0.560
[42,    11] loss: 0.560
[43,    11] loss: 0.564
[44,    11] loss: 0.572
[45,    11] loss: 0.567
[46,    11] loss: 0.575
[47,    11] loss: 0.563
[48,    11] loss: 0.566
[49,    11] loss: 0.574
[50,    11] loss: 0.571
[51,    11] loss: 0.570
[52,    11] loss: 0.561
[53,    11] loss: 0.550
[54,    11] loss: 0.566
[55,    11] loss: 0.575
[56,    11] loss: 0.584
[57,    11] loss: 0.572
[58,    11] loss: 0.559
[59,    11] loss: 0.575
[60,    11] loss: 0.565
[61,    11] loss: 0.565
[62,    11] loss: 0.566
[63,    11] loss: 0.555
[64,    11] loss: 0.560
[65,    11] loss: 0.555
[66,    11] loss: 0.568
[67,    11] loss: 0.563
[68,    11] loss: 0.568
[69,    11] loss: 0.587
[70,    11] loss: 0.569
[71,    11] loss: 0.559
[72,    11] loss: 0.566
[73,    11] loss: 0.558
[74,    11] loss: 0.556
[75,    11] loss: 0.545
[76,    11] loss: 0.565
[77,    11] loss: 0.561
[78,    11] loss: 0.566
[79,    11] loss: 0.562
[80,    11] loss: 0.563
[81,    11] loss: 0.558
[82,    11] loss: 0.576
[83,    11] loss: 0.574
[84,    11] loss: 0.553
[85,    11] loss: 0.577
[86,    11] loss: 0.573
[87,    11] loss: 0.555
[88,    11] loss: 0.565
[89,    11] loss: 0.544
[90,    11] loss: 0.551
[91,    11] loss: 0.552
[92,    11] loss: 0.558
[93,    11] loss: 0.553
[94,    11] loss: 0.559
[95,    11] loss: 0.562
[96,    11] loss: 0.565
[97,    11] loss: 0.557
[98,    11] loss: 0.554
[99,    11] loss: 0.546
[100,    11] loss: 0.552
[101,    11] loss: 0.557
[102,    11] loss: 0.555
[103,    11] loss: 0.547
[104,    11] loss: 0.573
[105,    11] loss: 0.551
[106,    11] loss: 0.558
[107,    11] loss: 0.545
[108,    11] loss: 0.559
[109,    11] loss: 0.554
[110,    11] loss: 0.554
[111,    11] loss: 0.546
[112,    11] loss: 0.556
[113,    11] loss: 0.560
[114,    11] loss: 0.551
[115,    11] loss: 0.557
[116,    11] loss: 0.553
[117,    11] loss: 0.556
[118,    11] loss: 0.553
[119,    11] loss: 0.558
[120,    11] loss: 0.554
[121,    11] loss: 0.574
[122,    11] loss: 0.567
[123,    11] loss: 0.557
[124,    11] loss: 0.557
[125,    11] loss: 0.560
[126,    11] loss: 0.562
[127,    11] loss: 0.572
[128,    11] loss: 0.559
[129,    11] loss: 0.552
[130,    11] loss: 0.562
[131,    11] loss: 0.565
[132,    11] loss: 0.559
[133,    11] loss: 0.567
[134,    11] loss: 0.565
[135,    11] loss: 0.566
[136,    11] loss: 0.553
[137,    11] loss: 0.553
[138,    11] loss: 0.553
[139,    11] loss: 0.548
[140,    11] loss: 0.553
[141,    11] loss: 0.554
[142,    11] loss: 0.562
[143,    11] loss: 0.552
[144,    11] loss: 0.546
[145,    11] loss: 0.547
[146,    11] loss: 0.540
[147,    11] loss: 0.557
[148,    11] loss: 0.574
[149,    11] loss: 0.562
[150,    11] loss: 0.564
[151,    11] loss: 0.547
[152,    11] loss: 0.563
[153,    11] loss: 0.558
[154,    11] loss: 0.566
[155,    11] loss: 0.558
[156,    11] loss: 0.558
[157,    11] loss: 0.564
[158,    11] loss: 0.558
[159,    11] loss: 0.551
Early stopping applied (best metric=0.37455859780311584)
Finished Training
Total time taken: 66.63187527656555
[1,     1] loss: 0.693
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.691
[5,    11] loss: 0.690
[6,    11] loss: 0.690
[7,    11] loss: 0.690
[8,    11] loss: 0.689
[9,    11] loss: 0.689
[10,    11] loss: 0.688
[11,    11] loss: 0.688
[12,    11] loss: 0.687
[13,    11] loss: 0.687
[14,    11] loss: 0.676
[15,    11] loss: 0.663
[16,    11] loss: 0.642
[17,    11] loss: 0.630
[18,    11] loss: 0.617
[19,    11] loss: 0.609
[20,    11] loss: 0.608
[21,    11] loss: 0.605
[22,    11] loss: 0.596
[23,    11] loss: 0.595
[24,    11] loss: 0.587
[25,    11] loss: 0.610
[26,    11] loss: 0.595
[27,    11] loss: 0.596
[28,    11] loss: 0.585
[29,    11] loss: 0.578
[30,    11] loss: 0.577
[31,    11] loss: 0.580
[32,    11] loss: 0.574
[33,    11] loss: 0.569
[34,    11] loss: 0.568
[35,    11] loss: 0.577
[36,    11] loss: 0.582
[37,    11] loss: 0.566
[38,    11] loss: 0.565
[39,    11] loss: 0.569
[40,    11] loss: 0.580
[41,    11] loss: 0.584
[42,    11] loss: 0.571
[43,    11] loss: 0.569
[44,    11] loss: 0.560
[45,    11] loss: 0.563
[46,    11] loss: 0.567
[47,    11] loss: 0.559
[48,    11] loss: 0.601
[49,    11] loss: 0.589
[50,    11] loss: 0.564
[51,    11] loss: 0.556
[52,    11] loss: 0.564
[53,    11] loss: 0.558
[54,    11] loss: 0.566
[55,    11] loss: 0.563
[56,    11] loss: 0.569
[57,    11] loss: 0.574
[58,    11] loss: 0.574
[59,    11] loss: 0.554
[60,    11] loss: 0.559
[61,    11] loss: 0.565
[62,    11] loss: 0.556
[63,    11] loss: 0.567
[64,    11] loss: 0.560
[65,    11] loss: 0.560
[66,    11] loss: 0.563
[67,    11] loss: 0.569
[68,    11] loss: 0.554
[69,    11] loss: 0.566
[70,    11] loss: 0.566
[71,    11] loss: 0.580
[72,    11] loss: 0.560
[73,    11] loss: 0.565
[74,    11] loss: 0.553
[75,    11] loss: 0.566
[76,    11] loss: 0.557
[77,    11] loss: 0.555
[78,    11] loss: 0.574
[79,    11] loss: 0.568
[80,    11] loss: 0.562
[81,    11] loss: 0.567
[82,    11] loss: 0.566
[83,    11] loss: 0.564
[84,    11] loss: 0.559
[85,    11] loss: 0.552
[86,    11] loss: 0.561
[87,    11] loss: 0.558
[88,    11] loss: 0.556
[89,    11] loss: 0.570
[90,    11] loss: 0.591
[91,    11] loss: 0.566
[92,    11] loss: 0.558
[93,    11] loss: 0.549
[94,    11] loss: 0.569
[95,    11] loss: 0.562
[96,    11] loss: 0.556
[97,    11] loss: 0.554
[98,    11] loss: 0.566
[99,    11] loss: 0.564
[100,    11] loss: 0.558
[101,    11] loss: 0.552
[102,    11] loss: 0.568
[103,    11] loss: 0.565
[104,    11] loss: 0.562
[105,    11] loss: 0.556
[106,    11] loss: 0.554
[107,    11] loss: 0.562
[108,    11] loss: 0.546
[109,    11] loss: 0.556
[110,    11] loss: 0.562
[111,    11] loss: 0.543
[112,    11] loss: 0.549
[113,    11] loss: 0.556
[114,    11] loss: 0.564
[115,    11] loss: 0.561
[116,    11] loss: 0.552
[117,    11] loss: 0.556
[118,    11] loss: 0.550
[119,    11] loss: 0.557
[120,    11] loss: 0.559
[121,    11] loss: 0.549
[122,    11] loss: 0.558
[123,    11] loss: 0.560
[124,    11] loss: 0.552
[125,    11] loss: 0.551
[126,    11] loss: 0.550
[127,    11] loss: 0.561
[128,    11] loss: 0.574
[129,    11] loss: 0.575
[130,    11] loss: 0.563
[131,    11] loss: 0.550
[132,    11] loss: 0.560
[133,    11] loss: 0.576
[134,    11] loss: 0.559
[135,    11] loss: 0.556
[136,    11] loss: 0.545
[137,    11] loss: 0.558
[138,    11] loss: 0.558
[139,    11] loss: 0.563
[140,    11] loss: 0.575
[141,    11] loss: 0.563
[142,    11] loss: 0.556
[143,    11] loss: 0.585
[144,    11] loss: 0.558
[145,    11] loss: 0.569
[146,    11] loss: 0.569
[147,    11] loss: 0.557
[148,    11] loss: 0.553
[149,    11] loss: 0.546
[150,    11] loss: 0.553
[151,    11] loss: 0.539
[152,    11] loss: 0.551
[153,    11] loss: 0.558
[154,    11] loss: 0.552
[155,    11] loss: 0.560
[156,    11] loss: 0.552
Early stopping applied (best metric=0.37015965580940247)
Finished Training
Total time taken: 63.80727243423462
{'Sumoylation Validation Accuracy': 0.6868690343559505, 'Sumoylation Validation Sensitivity': 0.7716805531777283, 'Sumoylation Validation Specificity': 0.6732978718865331, 'Sumoylation Validation Precision': 0.2762145148468503, 'Sumoylation AUC ROC': 0.8090510054161083, 'Sumoylation AUC PR': 0.5137246546813787, 'Sumoylation MCC': 0.31631936488759727, 'Sumoylation F1': 0.4059649261427868, 'Validation Loss (Sumoylation)': 0.3672137796878815, 'Validation Loss (total)': 0.3672137796878815, 'TimeToTrain': 62.63134818077087}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005949086747313861,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 450554337,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 8.77833188957768}
[1,     1] loss: 0.695
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.690
[11,    11] loss: 0.688
[12,    11] loss: 0.686
[13,    11] loss: 0.679
[14,    11] loss: 0.691
[15,    11] loss: 0.692
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007520717010182772,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1067389925,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 9.70976436669441}
[1,     1] loss: 0.691
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.692
[11,    11] loss: 0.692
[12,    11] loss: 0.692
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00045068686821932906,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 624746289,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 16.232858135414727}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007375471093592244,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2799471397,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 20.45853278655302}
[1,     1] loss: 0.690
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034224946833290555,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1635025503,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 12.847053361803395}
[1,     1] loss: 0.697
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.692
[12,    11] loss: 0.693
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.692
[42,    11] loss: 0.692
[43,    11] loss: 0.692
[44,    11] loss: 0.692
[45,    11] loss: 0.692
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.692
[52,    11] loss: 0.692
[53,    11] loss: 0.692
[54,    11] loss: 0.692
[55,    11] loss: 0.692
[56,    11] loss: 0.692
[57,    11] loss: 0.692
[58,    11] loss: 0.692
[59,    11] loss: 0.692
[60,    11] loss: 0.692
[61,    11] loss: 0.692
Early stopping applied (best metric=0.48890042304992676)
Finished Training
Total time taken: 24.74226450920105
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.692
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.693
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.693
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.693
[41,    11] loss: 0.693
[42,    11] loss: 0.692
[43,    11] loss: 0.693
[44,    11] loss: 0.693
[45,    11] loss: 0.693
[46,    11] loss: 0.693
[47,    11] loss: 0.693
[48,    11] loss: 0.693
[49,    11] loss: 0.693
[50,    11] loss: 0.693
[51,    11] loss: 0.693
[52,    11] loss: 0.693
[53,    11] loss: 0.693
Early stopping applied (best metric=0.4883366525173187)
Finished Training
Total time taken: 22.679018020629883
[1,     1] loss: 0.701
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.692
[42,    11] loss: 0.692
[43,    11] loss: 0.692
[44,    11] loss: 0.692
[45,    11] loss: 0.693
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.692
Early stopping applied (best metric=0.48733848333358765)
Finished Training
Total time taken: 21.758903741836548
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.693
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.692
[42,    11] loss: 0.692
[43,    11] loss: 0.692
[44,    11] loss: 0.692
[45,    11] loss: 0.692
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.692
[52,    11] loss: 0.692
[53,    11] loss: 0.692
[54,    11] loss: 0.692
[55,    11] loss: 0.692
[56,    11] loss: 0.692
[57,    11] loss: 0.692
[58,    11] loss: 0.692
[59,    11] loss: 0.692
[60,    11] loss: 0.692
[61,    11] loss: 0.692
[62,    11] loss: 0.692
[63,    11] loss: 0.692
[64,    11] loss: 0.692
[65,    11] loss: 0.692
[66,    11] loss: 0.692
[67,    11] loss: 0.692
[68,    11] loss: 0.692
[69,    11] loss: 0.692
[70,    11] loss: 0.692
[71,    11] loss: 0.692
[72,    11] loss: 0.692
[73,    11] loss: 0.692
[74,    11] loss: 0.692
[75,    11] loss: 0.692
[76,    11] loss: 0.692
[77,    11] loss: 0.692
[78,    11] loss: 0.693
[79,    11] loss: 0.692
[80,    11] loss: 0.692
[81,    11] loss: 0.692
[82,    11] loss: 0.692
[83,    11] loss: 0.692
Early stopping applied (best metric=0.48793089389801025)
Finished Training
Total time taken: 35.25550150871277
[1,     1] loss: 0.691
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.692
[11,    11] loss: 0.692
[12,    11] loss: 0.692
[13,    11] loss: 0.692
[14,    11] loss: 0.692
[15,    11] loss: 0.692
[16,    11] loss: 0.692
[17,    11] loss: 0.692
[18,    11] loss: 0.692
[19,    11] loss: 0.692
[20,    11] loss: 0.692
[21,    11] loss: 0.692
[22,    11] loss: 0.692
[23,    11] loss: 0.692
[24,    11] loss: 0.692
[25,    11] loss: 0.692
[26,    11] loss: 0.692
[27,    11] loss: 0.692
[28,    11] loss: 0.692
[29,    11] loss: 0.692
[30,    11] loss: 0.692
[31,    11] loss: 0.692
[32,    11] loss: 0.692
[33,    11] loss: 0.692
[34,    11] loss: 0.692
[35,    11] loss: 0.692
[36,    11] loss: 0.692
[37,    11] loss: 0.692
[38,    11] loss: 0.692
[39,    11] loss: 0.692
[40,    11] loss: 0.692
[41,    11] loss: 0.692
[42,    11] loss: 0.692
[43,    11] loss: 0.692
[44,    11] loss: 0.692
[45,    11] loss: 0.692
[46,    11] loss: 0.692
[47,    11] loss: 0.692
[48,    11] loss: 0.692
[49,    11] loss: 0.692
[50,    11] loss: 0.692
[51,    11] loss: 0.692
Early stopping applied (best metric=0.48674729466438293)
Finished Training
Total time taken: 21.441502571105957
{'Sumoylation Validation Accuracy': 0.1911276505167432, 'Sumoylation Validation Sensitivity': 0.974393654054671, 'Sumoylation Validation Specificity': 0.06577362090140827, 'Sumoylation Validation Precision': 0.1430839056143896, 'Sumoylation AUC ROC': 0.6036119533421112, 'Sumoylation AUC PR': 0.3650201697910159, 'Sumoylation MCC': 0.05793271348564219, 'Sumoylation F1': 0.2495115073979918, 'Validation Loss (Sumoylation)': 0.4878507494926453, 'Validation Loss (total)': 0.4878507494926453, 'TimeToTrain': 25.17543807029724}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001503618697932094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1599716206,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 22.842832391636698}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007033368345264952,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1258448710,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 13.288819679484323}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.691
[10,    11] loss: 0.689
[11,    11] loss: 0.686
[12,    11] loss: 0.682
[13,    11] loss: 0.671
[14,    11] loss: 0.667
[15,    11] loss: 0.662
[16,    11] loss: 0.655
[17,    11] loss: 0.648
[18,    11] loss: 0.648
[19,    11] loss: 0.642
[20,    11] loss: 0.626
[21,    11] loss: 0.617
[22,    11] loss: 0.610
[23,    11] loss: 0.613
[24,    11] loss: 0.608
[25,    11] loss: 0.623
[26,    11] loss: 0.605
[27,    11] loss: 0.610
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042929889483626655,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 189491187,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 23.566582196067685}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00552106773246764,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1761225901,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 17.192620051528074}
[1,     1] loss: 0.692
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007932189118671138,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 14730616,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.243292246617373}
[1,     1] loss: 0.692
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.690
[5,    11] loss: 0.689
[6,    11] loss: 0.687
[7,    11] loss: 0.687
[8,    11] loss: 0.687
[9,    11] loss: 0.687
[10,    11] loss: 0.687
[11,    11] loss: 0.688
[12,    11] loss: 0.687
[13,    11] loss: 0.688
[14,    11] loss: 0.687
[15,    11] loss: 0.687
[16,    11] loss: 0.676
[17,    11] loss: 0.688
[18,    11] loss: 0.688
[19,    11] loss: 0.688
[20,    11] loss: 0.687
[21,    11] loss: 0.686
[22,    11] loss: 0.679
[23,    11] loss: 0.662
[24,    11] loss: 0.656
[25,    11] loss: 0.657
[26,    11] loss: 0.633
[27,    11] loss: 0.623
[28,    11] loss: 0.617
[29,    11] loss: 0.607
[30,    11] loss: 0.616
[31,    11] loss: 0.619
[32,    11] loss: 0.622
[33,    11] loss: 0.616
[34,    11] loss: 0.602
[35,    11] loss: 0.610
[36,    11] loss: 0.609
[37,    11] loss: 0.603
[38,    11] loss: 0.606
[39,    11] loss: 0.605
[40,    11] loss: 0.606
[41,    11] loss: 0.605
[42,    11] loss: 0.601
[43,    11] loss: 0.607
[44,    11] loss: 0.614
[45,    11] loss: 0.600
[46,    11] loss: 0.609
[47,    11] loss: 0.619
[48,    11] loss: 0.605
[49,    11] loss: 0.591
[50,    11] loss: 0.601
[51,    11] loss: 0.603
[52,    11] loss: 0.614
[53,    11] loss: 0.602
[54,    11] loss: 0.606
[55,    11] loss: 0.621
[56,    11] loss: 0.622
[57,    11] loss: 0.602
[58,    11] loss: 0.596
[59,    11] loss: 0.626
[60,    11] loss: 0.596
[61,    11] loss: 0.616
[62,    11] loss: 0.599
[63,    11] loss: 0.603
[64,    11] loss: 0.600
[65,    11] loss: 0.599
[66,    11] loss: 0.606
[67,    11] loss: 0.628
[68,    11] loss: 0.604
[69,    11] loss: 0.610
[70,    11] loss: 0.595
[71,    11] loss: 0.606
[72,    11] loss: 0.612
[73,    11] loss: 0.589
[74,    11] loss: 0.599
[75,    11] loss: 0.601
[76,    11] loss: 0.624
[77,    11] loss: 0.608
[78,    11] loss: 0.599
[79,    11] loss: 0.593
[80,    11] loss: 0.600
[81,    11] loss: 0.609
[82,    11] loss: 0.598
[83,    11] loss: 0.600
[84,    11] loss: 0.596
[85,    11] loss: 0.610
[86,    11] loss: 0.598
[87,    11] loss: 0.602
[88,    11] loss: 0.601
[89,    11] loss: 0.593
[90,    11] loss: 0.606
[91,    11] loss: 0.588
[92,    11] loss: 0.598
[93,    11] loss: 0.606
[94,    11] loss: 0.609
[95,    11] loss: 0.589
[96,    11] loss: 0.591
[97,    11] loss: 0.596
[98,    11] loss: 0.596
[99,    11] loss: 0.596
[100,    11] loss: 0.596
[101,    11] loss: 0.603
[102,    11] loss: 0.600
[103,    11] loss: 0.598
[104,    11] loss: 0.596
[105,    11] loss: 0.588
[106,    11] loss: 0.603
[107,    11] loss: 0.591
[108,    11] loss: 0.601
[109,    11] loss: 0.600
[110,    11] loss: 0.605
[111,    11] loss: 0.579
[112,    11] loss: 0.603
[113,    11] loss: 0.597
[114,    11] loss: 0.607
[115,    11] loss: 0.600
[116,    11] loss: 0.602
[117,    11] loss: 0.608
[118,    11] loss: 0.596
[119,    11] loss: 0.588
[120,    11] loss: 0.603
[121,    11] loss: 0.597
[122,    11] loss: 0.607
[123,    11] loss: 0.604
[124,    11] loss: 0.609
[125,    11] loss: 0.597
[126,    11] loss: 0.600
[127,    11] loss: 0.597
[128,    11] loss: 0.606
[129,    11] loss: 0.598
[130,    11] loss: 0.618
[131,    11] loss: 0.604
[132,    11] loss: 0.604
Early stopping applied (best metric=0.3934433162212372)
Finished Training
Total time taken: 55.54900813102722
[1,     1] loss: 0.694
[2,    11] loss: 0.692
[3,    11] loss: 0.691
[4,    11] loss: 0.689
[5,    11] loss: 0.689
[6,    11] loss: 0.688
[7,    11] loss: 0.689
[8,    11] loss: 0.687
[9,    11] loss: 0.685
[10,    11] loss: 0.674
[11,    11] loss: 0.669
[12,    11] loss: 0.640
[13,    11] loss: 0.631
[14,    11] loss: 0.636
[15,    11] loss: 0.626
[16,    11] loss: 0.610
[17,    11] loss: 0.604
[18,    11] loss: 0.625
[19,    11] loss: 0.624
[20,    11] loss: 0.610
[21,    11] loss: 0.609
[22,    11] loss: 0.607
[23,    11] loss: 0.605
[24,    11] loss: 0.612
[25,    11] loss: 0.592
[26,    11] loss: 0.607
[27,    11] loss: 0.630
[28,    11] loss: 0.605
[29,    11] loss: 0.586
[30,    11] loss: 0.595
[31,    11] loss: 0.641
[32,    11] loss: 0.611
[33,    11] loss: 0.616
[34,    11] loss: 0.600
[35,    11] loss: 0.633
[36,    11] loss: 0.608
[37,    11] loss: 0.609
[38,    11] loss: 0.620
[39,    11] loss: 0.602
[40,    11] loss: 0.612
[41,    11] loss: 0.635
[42,    11] loss: 0.597
[43,    11] loss: 0.605
[44,    11] loss: 0.595
[45,    11] loss: 0.614
[46,    11] loss: 0.607
[47,    11] loss: 0.600
[48,    11] loss: 0.607
[49,    11] loss: 0.610
[50,    11] loss: 0.637
[51,    11] loss: 0.599
[52,    11] loss: 0.617
[53,    11] loss: 0.607
[54,    11] loss: 0.591
[55,    11] loss: 0.593
[56,    11] loss: 0.600
[57,    11] loss: 0.599
[58,    11] loss: 0.601
[59,    11] loss: 0.609
[60,    11] loss: 0.609
[61,    11] loss: 0.592
[62,    11] loss: 0.599
[63,    11] loss: 0.599
[64,    11] loss: 0.599
[65,    11] loss: 0.608
[66,    11] loss: 0.598
[67,    11] loss: 0.600
[68,    11] loss: 0.599
[69,    11] loss: 0.589
[70,    11] loss: 0.590
[71,    11] loss: 0.605
[72,    11] loss: 0.590
[73,    11] loss: 0.601
[74,    11] loss: 0.619
[75,    11] loss: 0.598
[76,    11] loss: 0.606
[77,    11] loss: 0.600
[78,    11] loss: 0.601
[79,    11] loss: 0.598
[80,    11] loss: 0.589
[81,    11] loss: 0.586
[82,    11] loss: 0.609
[83,    11] loss: 0.650
[84,    11] loss: 0.598
[85,    11] loss: 0.607
[86,    11] loss: 0.597
[87,    11] loss: 0.581
[88,    11] loss: 0.600
[89,    11] loss: 0.605
[90,    11] loss: 0.597
[91,    11] loss: 0.620
[92,    11] loss: 0.607
[93,    11] loss: 0.606
[94,    11] loss: 0.612
[95,    11] loss: 0.602
[96,    11] loss: 0.600
Early stopping applied (best metric=0.38742169737815857)
Finished Training
Total time taken: 40.08322310447693
[1,     1] loss: 0.693
[2,    11] loss: 0.692
[3,    11] loss: 0.690
[4,    11] loss: 0.689
[5,    11] loss: 0.688
[6,    11] loss: 0.688
[7,    11] loss: 0.687
[8,    11] loss: 0.686
[9,    11] loss: 0.687
[10,    11] loss: 0.686
[11,    11] loss: 0.672
[12,    11] loss: 0.665
[13,    11] loss: 0.668
[14,    11] loss: 0.649
[15,    11] loss: 0.632
[16,    11] loss: 0.616
[17,    11] loss: 0.600
[18,    11] loss: 0.640
[19,    11] loss: 0.615
[20,    11] loss: 0.610
[21,    11] loss: 0.612
[22,    11] loss: 0.600
[23,    11] loss: 0.619
[24,    11] loss: 0.618
[25,    11] loss: 0.601
[26,    11] loss: 0.626
[27,    11] loss: 0.602
[28,    11] loss: 0.599
[29,    11] loss: 0.599
[30,    11] loss: 0.598
[31,    11] loss: 0.609
[32,    11] loss: 0.608
[33,    11] loss: 0.595
[34,    11] loss: 0.621
[35,    11] loss: 0.605
[36,    11] loss: 0.597
[37,    11] loss: 0.594
[38,    11] loss: 0.607
[39,    11] loss: 0.604
[40,    11] loss: 0.605
[41,    11] loss: 0.594
[42,    11] loss: 0.610
[43,    11] loss: 0.625
[44,    11] loss: 0.608
[45,    11] loss: 0.590
[46,    11] loss: 0.583
[47,    11] loss: 0.589
[48,    11] loss: 0.622
[49,    11] loss: 0.601
[50,    11] loss: 0.592
[51,    11] loss: 0.582
[52,    11] loss: 0.610
[53,    11] loss: 0.607
[54,    11] loss: 0.590
[55,    11] loss: 0.591
[56,    11] loss: 0.585
[57,    11] loss: 0.601
[58,    11] loss: 0.600
[59,    11] loss: 0.603
[60,    11] loss: 0.592
[61,    11] loss: 0.595
[62,    11] loss: 0.625
[63,    11] loss: 0.596
[64,    11] loss: 0.610
[65,    11] loss: 0.602
[66,    11] loss: 0.592
[67,    11] loss: 0.593
[68,    11] loss: 0.597
[69,    11] loss: 0.600
[70,    11] loss: 0.591
[71,    11] loss: 0.601
[72,    11] loss: 0.597
[73,    11] loss: 0.588
[74,    11] loss: 0.597
[75,    11] loss: 0.604
[76,    11] loss: 0.610
[77,    11] loss: 0.606
[78,    11] loss: 0.594
[79,    11] loss: 0.591
[80,    11] loss: 0.600
[81,    11] loss: 0.598
[82,    11] loss: 0.604
[83,    11] loss: 0.609
[84,    11] loss: 0.607
[85,    11] loss: 0.597
[86,    11] loss: 0.595
[87,    11] loss: 0.601
[88,    11] loss: 0.585
[89,    11] loss: 0.585
[90,    11] loss: 0.600
[91,    11] loss: 0.601
[92,    11] loss: 0.602
[93,    11] loss: 0.605
[94,    11] loss: 0.614
[95,    11] loss: 0.614
[96,    11] loss: 0.603
[97,    11] loss: 0.599
[98,    11] loss: 0.598
[99,    11] loss: 0.596
[100,    11] loss: 0.599
[101,    11] loss: 0.607
[102,    11] loss: 0.597
[103,    11] loss: 0.610
[104,    11] loss: 0.601
[105,    11] loss: 0.595
[106,    11] loss: 0.611
[107,    11] loss: 0.639
[108,    11] loss: 0.603
[109,    11] loss: 0.593
[110,    11] loss: 0.606
[111,    11] loss: 0.612
[112,    11] loss: 0.598
[113,    11] loss: 0.606
[114,    11] loss: 0.613
[115,    11] loss: 0.669
[116,    11] loss: 0.609
[117,    11] loss: 0.599
[118,    11] loss: 0.617
[119,    11] loss: 0.600
[120,    11] loss: 0.595
[121,    11] loss: 0.603
[122,    11] loss: 0.613
[123,    11] loss: 0.605
[124,    11] loss: 0.597
[125,    11] loss: 0.606
[126,    11] loss: 0.612
[127,    11] loss: 0.607
[128,    11] loss: 0.605
[129,    11] loss: 0.603
[130,    11] loss: 0.596
[131,    11] loss: 0.609
[132,    11] loss: 0.596
[133,    11] loss: 0.613
[134,    11] loss: 0.599
[135,    11] loss: 0.583
[136,    11] loss: 0.604
[137,    11] loss: 0.614
[138,    11] loss: 0.607
[139,    11] loss: 0.591
Early stopping applied (best metric=0.3824700713157654)
Finished Training
Total time taken: 57.455220460891724
[1,     1] loss: 0.702
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.690
[6,    11] loss: 0.691
[7,    11] loss: 0.690
[8,    11] loss: 0.689
[9,    11] loss: 0.690
[10,    11] loss: 0.688
[11,    11] loss: 0.683
[12,    11] loss: 0.669
[13,    11] loss: 0.668
[14,    11] loss: 0.653
[15,    11] loss: 0.652
[16,    11] loss: 0.647
[17,    11] loss: 0.644
[18,    11] loss: 0.629
[19,    11] loss: 0.623
[20,    11] loss: 0.614
[21,    11] loss: 0.633
[22,    11] loss: 0.617
[23,    11] loss: 0.621
[24,    11] loss: 0.610
[25,    11] loss: 0.606
[26,    11] loss: 0.605
[27,    11] loss: 0.613
[28,    11] loss: 0.600
[29,    11] loss: 0.617
[30,    11] loss: 0.600
[31,    11] loss: 0.602
[32,    11] loss: 0.625
[33,    11] loss: 0.637
[34,    11] loss: 0.612
[35,    11] loss: 0.608
[36,    11] loss: 0.604
[37,    11] loss: 0.630
[38,    11] loss: 0.617
[39,    11] loss: 0.600
[40,    11] loss: 0.628
[41,    11] loss: 0.599
[42,    11] loss: 0.607
[43,    11] loss: 0.595
[44,    11] loss: 0.663
[45,    11] loss: 0.622
[46,    11] loss: 0.632
[47,    11] loss: 0.610
[48,    11] loss: 0.611
[49,    11] loss: 0.603
[50,    11] loss: 0.602
[51,    11] loss: 0.595
[52,    11] loss: 0.634
[53,    11] loss: 0.614
[54,    11] loss: 0.607
[55,    11] loss: 0.610
[56,    11] loss: 0.600
[57,    11] loss: 0.594
[58,    11] loss: 0.608
[59,    11] loss: 0.636
[60,    11] loss: 0.603
[61,    11] loss: 0.607
[62,    11] loss: 0.588
[63,    11] loss: 0.626
[64,    11] loss: 0.604
[65,    11] loss: 0.604
[66,    11] loss: 0.604
[67,    11] loss: 0.613
[68,    11] loss: 0.604
[69,    11] loss: 0.604
[70,    11] loss: 0.600
[71,    11] loss: 0.599
[72,    11] loss: 0.606
[73,    11] loss: 0.603
[74,    11] loss: 0.618
[75,    11] loss: 0.626
[76,    11] loss: 0.612
[77,    11] loss: 0.589
[78,    11] loss: 0.601
[79,    11] loss: 0.609
[80,    11] loss: 0.602
[81,    11] loss: 0.604
[82,    11] loss: 0.609
[83,    11] loss: 0.594
[84,    11] loss: 0.597
[85,    11] loss: 0.611
[86,    11] loss: 0.612
[87,    11] loss: 0.603
[88,    11] loss: 0.609
[89,    11] loss: 0.607
[90,    11] loss: 0.607
[91,    11] loss: 0.600
[92,    11] loss: 0.605
[93,    11] loss: 0.607
[94,    11] loss: 0.602
[95,    11] loss: 0.606
[96,    11] loss: 0.617
[97,    11] loss: 0.613
[98,    11] loss: 0.601
[99,    11] loss: 0.604
[100,    11] loss: 0.629
[101,    11] loss: 0.603
[102,    11] loss: 0.598
[103,    11] loss: 0.604
[104,    11] loss: 0.591
[105,    11] loss: 0.633
[106,    11] loss: 0.601
[107,    11] loss: 0.612
[108,    11] loss: 0.594
[109,    11] loss: 0.602
[110,    11] loss: 0.645
[111,    11] loss: 0.627
[112,    11] loss: 0.602
[113,    11] loss: 0.600
[114,    11] loss: 0.610
[115,    11] loss: 0.616
[116,    11] loss: 0.595
[117,    11] loss: 0.614
[118,    11] loss: 0.590
[119,    11] loss: 0.613
[120,    11] loss: 0.595
[121,    11] loss: 0.599
[122,    11] loss: 0.598
[123,    11] loss: 0.622
[124,    11] loss: 0.650
[125,    11] loss: 0.610
[126,    11] loss: 0.600
[127,    11] loss: 0.609
[128,    11] loss: 0.619
[129,    11] loss: 0.625
[130,    11] loss: 0.610
[131,    11] loss: 0.609
[132,    11] loss: 0.615
[133,    11] loss: 0.604
[134,    11] loss: 0.612
[135,    11] loss: 0.609
[136,    11] loss: 0.611
[137,    11] loss: 0.622
[138,    11] loss: 0.593
[139,    11] loss: 0.607
[140,    11] loss: 0.599
[141,    11] loss: 0.610
[142,    11] loss: 0.606
[143,    11] loss: 0.604
[144,    11] loss: 0.613
[145,    11] loss: 0.626
[146,    11] loss: 0.625
[147,    11] loss: 0.596
[148,    11] loss: 0.605
[149,    11] loss: 0.610
[150,    11] loss: 0.610
[151,    11] loss: 0.611
[152,    11] loss: 0.615
[153,    11] loss: 0.614
[154,    11] loss: 0.597
[155,    11] loss: 0.602
[156,    11] loss: 0.602
[157,    11] loss: 0.598
[158,    11] loss: 0.595
[159,    11] loss: 0.603
[160,    11] loss: 0.607
[161,    11] loss: 0.614
[162,    11] loss: 0.614
[163,    11] loss: 0.601
[164,    11] loss: 0.623
[165,    11] loss: 0.608
[166,    11] loss: 0.595
[167,    11] loss: 0.601
[168,    11] loss: 0.602
[169,    11] loss: 0.597
[170,    11] loss: 0.599
[171,    11] loss: 0.619
[172,    11] loss: 0.613
[173,    11] loss: 0.606
[174,    11] loss: 0.606
[175,    11] loss: 0.601
[176,    11] loss: 0.601
[177,    11] loss: 0.603
[178,    11] loss: 0.614
[179,    11] loss: 0.608
[180,    11] loss: 0.597
[181,    11] loss: 0.619
[182,    11] loss: 0.599
[183,    11] loss: 0.602
[184,    11] loss: 0.615
[185,    11] loss: 0.596
[186,    11] loss: 0.604
[187,    11] loss: 0.598
[188,    11] loss: 0.617
[189,    11] loss: 0.588
[190,    11] loss: 0.592
[191,    11] loss: 0.615
[192,    11] loss: 0.602
[193,    11] loss: 0.604
[194,    11] loss: 0.602
[195,    11] loss: 0.601
[196,    11] loss: 0.619
[197,    11] loss: 0.608
[198,    11] loss: 0.598
[199,    11] loss: 0.590
[200,    11] loss: 0.610
Finished Training
Total time taken: 82.47966599464417
[1,     1] loss: 0.694
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.690
[5,    11] loss: 0.690
[6,    11] loss: 0.688
[7,    11] loss: 0.688
[8,    11] loss: 0.687
[9,    11] loss: 0.687
[10,    11] loss: 0.687
[11,    11] loss: 0.689
[12,    11] loss: 0.688
[13,    11] loss: 0.682
[14,    11] loss: 0.686
[15,    11] loss: 0.679
[16,    11] loss: 0.678
[17,    11] loss: 0.667
[18,    11] loss: 0.660
[19,    11] loss: 0.642
[20,    11] loss: 0.630
[21,    11] loss: 0.651
[22,    11] loss: 0.626
[23,    11] loss: 0.630
[24,    11] loss: 0.616
[25,    11] loss: 0.629
[26,    11] loss: 0.619
[27,    11] loss: 0.623
[28,    11] loss: 0.622
[29,    11] loss: 0.616
[30,    11] loss: 0.624
[31,    11] loss: 0.620
[32,    11] loss: 0.615
[33,    11] loss: 0.614
[34,    11] loss: 0.613
[35,    11] loss: 0.601
[36,    11] loss: 0.616
[37,    11] loss: 0.604
[38,    11] loss: 0.609
[39,    11] loss: 0.616
[40,    11] loss: 0.607
[41,    11] loss: 0.592
[42,    11] loss: 0.609
[43,    11] loss: 0.602
[44,    11] loss: 0.614
[45,    11] loss: 0.616
[46,    11] loss: 0.618
[47,    11] loss: 0.607
[48,    11] loss: 0.602
[49,    11] loss: 0.592
[50,    11] loss: 0.601
[51,    11] loss: 0.611
[52,    11] loss: 0.612
[53,    11] loss: 0.608
[54,    11] loss: 0.615
[55,    11] loss: 0.599
[56,    11] loss: 0.601
[57,    11] loss: 0.592
[58,    11] loss: 0.598
[59,    11] loss: 0.595
[60,    11] loss: 0.596
[61,    11] loss: 0.596
[62,    11] loss: 0.619
[63,    11] loss: 0.599
[64,    11] loss: 0.612
[65,    11] loss: 0.593
[66,    11] loss: 0.590
[67,    11] loss: 0.599
[68,    11] loss: 0.604
[69,    11] loss: 0.607
[70,    11] loss: 0.625
[71,    11] loss: 0.594
[72,    11] loss: 0.603
[73,    11] loss: 0.599
[74,    11] loss: 0.617
[75,    11] loss: 0.589
[76,    11] loss: 0.587
[77,    11] loss: 0.585
[78,    11] loss: 0.587
[79,    11] loss: 0.586
[80,    11] loss: 0.604
[81,    11] loss: 0.610
[82,    11] loss: 0.582
[83,    11] loss: 0.602
[84,    11] loss: 0.588
[85,    11] loss: 0.598
[86,    11] loss: 0.595
[87,    11] loss: 0.586
[88,    11] loss: 0.592
[89,    11] loss: 0.596
[90,    11] loss: 0.610
[91,    11] loss: 0.603
[92,    11] loss: 0.600
[93,    11] loss: 0.614
[94,    11] loss: 0.596
[95,    11] loss: 0.604
[96,    11] loss: 0.607
[97,    11] loss: 0.608
[98,    11] loss: 0.591
[99,    11] loss: 0.589
[100,    11] loss: 0.611
[101,    11] loss: 0.586
[102,    11] loss: 0.600
[103,    11] loss: 0.596
[104,    11] loss: 0.624
[105,    11] loss: 0.597
[106,    11] loss: 0.600
[107,    11] loss: 0.593
[108,    11] loss: 0.597
[109,    11] loss: 0.593
[110,    11] loss: 0.603
[111,    11] loss: 0.597
[112,    11] loss: 0.605
[113,    11] loss: 0.609
[114,    11] loss: 0.610
[115,    11] loss: 0.594
[116,    11] loss: 0.612
[117,    11] loss: 0.621
[118,    11] loss: 0.594
[119,    11] loss: 0.590
[120,    11] loss: 0.616
[121,    11] loss: 0.593
[122,    11] loss: 0.590
[123,    11] loss: 0.592
[124,    11] loss: 0.604
[125,    11] loss: 0.605
[126,    11] loss: 0.594
[127,    11] loss: 0.623
[128,    11] loss: 0.599
[129,    11] loss: 0.599
[130,    11] loss: 0.609
[131,    11] loss: 0.620
[132,    11] loss: 0.598
[133,    11] loss: 0.613
[134,    11] loss: 0.600
[135,    11] loss: 0.612
Early stopping applied (best metric=0.39213037490844727)
Finished Training
Total time taken: 59.702641010284424
{'Sumoylation Validation Accuracy': 0.6756764761827124, 'Sumoylation Validation Sensitivity': 0.7473021172173715, 'Sumoylation Validation Specificity': 0.6642138292328369, 'Sumoylation Validation Precision': 0.2637887571878662, 'Sumoylation AUC ROC': 0.7840334419997691, 'Sumoylation AUC PR': 0.4352259718552601, 'Sumoylation MCC': 0.2914320876072002, 'Sumoylation F1': 0.3894576333397408, 'Validation Loss (Sumoylation)': 0.3870860874652863, 'Validation Loss (total)': 0.3870860874652863, 'TimeToTrain': 59.05395174026489}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006771746811842409,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2662474111,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 15.791278029805675}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004977271900332589,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1005345454,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 24.328888685054753}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00919491489575612,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1033605723,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 14.62735704403803}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006165960525576989,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 169442083,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 0.9486809646517602}
[1,     1] loss: 0.695
[2,    11] loss: 0.691
[3,    11] loss: 0.689
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008552520930075384,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 193675889,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 13.11122878822118}
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.693
[8,    11] loss: 0.692
[9,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007956717242885908,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 4231516483,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 23.92546115704946}
[1,     1] loss: 0.699
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003436357622952473,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3241584648,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 4.856254328823761}
[1,     1] loss: 0.694
[2,    11] loss: 0.694
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.691
[8,    11] loss: 0.691
[9,    11] loss: 0.689
[10,    11] loss: 0.675
[11,    11] loss: 0.653
[12,    11] loss: 0.627
[13,    11] loss: 0.627
[14,    11] loss: 0.608
[15,    11] loss: 0.609
[16,    11] loss: 0.613
[17,    11] loss: 0.597
[18,    11] loss: 0.602
[19,    11] loss: 0.599
[20,    11] loss: 0.599
[21,    11] loss: 0.589
[22,    11] loss: 0.585
[23,    11] loss: 0.600
[24,    11] loss: 0.589
[25,    11] loss: 0.582
[26,    11] loss: 0.594
[27,    11] loss: 0.587
[28,    11] loss: 0.579
[29,    11] loss: 0.587
[30,    11] loss: 0.595
[31,    11] loss: 0.608
[32,    11] loss: 0.597
[33,    11] loss: 0.600
[34,    11] loss: 0.608
[35,    11] loss: 0.591
[36,    11] loss: 0.581
[37,    11] loss: 0.577
[38,    11] loss: 0.595
[39,    11] loss: 0.600
[40,    11] loss: 0.585
[41,    11] loss: 0.596
[42,    11] loss: 0.598
[43,    11] loss: 0.590
[44,    11] loss: 0.585
[45,    11] loss: 0.587
[46,    11] loss: 0.584
[47,    11] loss: 0.600
[48,    11] loss: 0.595
[49,    11] loss: 0.581
[50,    11] loss: 0.582
[51,    11] loss: 0.603
[52,    11] loss: 0.593
[53,    11] loss: 0.591
[54,    11] loss: 0.590
[55,    11] loss: 0.608
[56,    11] loss: 0.605
[57,    11] loss: 0.601
[58,    11] loss: 0.598
[59,    11] loss: 0.595
[60,    11] loss: 0.586
[61,    11] loss: 0.592
[62,    11] loss: 0.589
[63,    11] loss: 0.590
[64,    11] loss: 0.582
[65,    11] loss: 0.597
[66,    11] loss: 0.593
[67,    11] loss: 0.600
[68,    11] loss: 0.579
[69,    11] loss: 0.606
[70,    11] loss: 0.598
[71,    11] loss: 0.590
[72,    11] loss: 0.600
[73,    11] loss: 0.595
[74,    11] loss: 0.595
[75,    11] loss: 0.614
[76,    11] loss: 0.592
[77,    11] loss: 0.590
[78,    11] loss: 0.590
[79,    11] loss: 0.597
[80,    11] loss: 0.605
[81,    11] loss: 0.594
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002295865442873824,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1758932407,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 9.247708905228901}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019428164833004446,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1937550965,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 23.58220681678837}
[1,     1] loss: 0.702
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009998091070575274,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3922958476,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.0317834140276396}
[1,     1] loss: 0.692
[2,    11] loss: 0.692
[3,    11] loss: 0.693
[4,    11] loss: 0.691
[5,    11] loss: 0.688
[6,    11] loss: 0.686
[7,    11] loss: 0.687
[8,    11] loss: 0.686
[9,    11] loss: 0.685
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008984899128257446,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2565717888,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 10.750003903948}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00658035018756048,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 527567939,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 8.627725890425706}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008317008944322828,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3299064750,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 4.896425903157267}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.691
[9,    11] loss: 0.690
[10,    11] loss: 0.683
[11,    11] loss: 0.674
[12,    11] loss: 0.664
[13,    11] loss: 0.666
[14,    11] loss: 0.643
[15,    11] loss: 0.640
[16,    11] loss: 0.635
[17,    11] loss: 0.631
[18,    11] loss: 0.620
[19,    11] loss: 0.615
[20,    11] loss: 0.620
[21,    11] loss: 0.606
[22,    11] loss: 0.605
[23,    11] loss: 0.602
[24,    11] loss: 0.597
[25,    11] loss: 0.606
[26,    11] loss: 0.603
[27,    11] loss: 0.602
[28,    11] loss: 0.591
[29,    11] loss: 0.601
[30,    11] loss: 0.602
[31,    11] loss: 0.594
[32,    11] loss: 0.588
[33,    11] loss: 0.598
[34,    11] loss: 0.582
[35,    11] loss: 0.590
[36,    11] loss: 0.603
[37,    11] loss: 0.582
[38,    11] loss: 0.597
[39,    11] loss: 0.600
[40,    11] loss: 0.583
[41,    11] loss: 0.588
[42,    11] loss: 0.585
[43,    11] loss: 0.584
[44,    11] loss: 0.576
[45,    11] loss: 0.575
[46,    11] loss: 0.577
[47,    11] loss: 0.576
[48,    11] loss: 0.580
[49,    11] loss: 0.584
[50,    11] loss: 0.579
[51,    11] loss: 0.569
[52,    11] loss: 0.572
[53,    11] loss: 0.571
[54,    11] loss: 0.571
[55,    11] loss: 0.570
[56,    11] loss: 0.567
[57,    11] loss: 0.563
[58,    11] loss: 0.569
[59,    11] loss: 0.564
[60,    11] loss: 0.572
[61,    11] loss: 0.565
[62,    11] loss: 0.556
[63,    11] loss: 0.563
[64,    11] loss: 0.571
[65,    11] loss: 0.570
[66,    11] loss: 0.566
[67,    11] loss: 0.561
[68,    11] loss: 0.563
[69,    11] loss: 0.567
[70,    11] loss: 0.549
[71,    11] loss: 0.568
[72,    11] loss: 0.561
[73,    11] loss: 0.558
[74,    11] loss: 0.569
[75,    11] loss: 0.561
[76,    11] loss: 0.553
[77,    11] loss: 0.563
[78,    11] loss: 0.574
[79,    11] loss: 0.562
[80,    11] loss: 0.549
[81,    11] loss: 0.552
[82,    11] loss: 0.550
[83,    11] loss: 0.557
[84,    11] loss: 0.545
[85,    11] loss: 0.562
[86,    11] loss: 0.559
[87,    11] loss: 0.563
[88,    11] loss: 0.554
[89,    11] loss: 0.571
[90,    11] loss: 0.558
[91,    11] loss: 0.544
[92,    11] loss: 0.561
[93,    11] loss: 0.558
[94,    11] loss: 0.573
[95,    11] loss: 0.555
[96,    11] loss: 0.553
[97,    11] loss: 0.550
[98,    11] loss: 0.557
[99,    11] loss: 0.557
[100,    11] loss: 0.558
[101,    11] loss: 0.563
[102,    11] loss: 0.553
[103,    11] loss: 0.561
[104,    11] loss: 0.556
[105,    11] loss: 0.569
[106,    11] loss: 0.553
[107,    11] loss: 0.547
[108,    11] loss: 0.571
[109,    11] loss: 0.553
[110,    11] loss: 0.561
[111,    11] loss: 0.552
[112,    11] loss: 0.551
[113,    11] loss: 0.552
[114,    11] loss: 0.565
[115,    11] loss: 0.554
[116,    11] loss: 0.552
[117,    11] loss: 0.555
[118,    11] loss: 0.564
[119,    11] loss: 0.550
[120,    11] loss: 0.559
[121,    11] loss: 0.545
[122,    11] loss: 0.553
[123,    11] loss: 0.545
[124,    11] loss: 0.560
[125,    11] loss: 0.555
[126,    11] loss: 0.557
[127,    11] loss: 0.552
[128,    11] loss: 0.548
[129,    11] loss: 0.575
[130,    11] loss: 0.544
[131,    11] loss: 0.551
[132,    11] loss: 0.558
[133,    11] loss: 0.550
[134,    11] loss: 0.546
[135,    11] loss: 0.559
[136,    11] loss: 0.547
[137,    11] loss: 0.558
[138,    11] loss: 0.562
[139,    11] loss: 0.561
[140,    11] loss: 0.551
[141,    11] loss: 0.559
[142,    11] loss: 0.555
[143,    11] loss: 0.545
[144,    11] loss: 0.548
[145,    11] loss: 0.552
[146,    11] loss: 0.554
[147,    11] loss: 0.560
[148,    11] loss: 0.578
[149,    11] loss: 0.554
[150,    11] loss: 0.554
[151,    11] loss: 0.557
[152,    11] loss: 0.552
[153,    11] loss: 0.566
[154,    11] loss: 0.555
[155,    11] loss: 0.570
[156,    11] loss: 0.562
[157,    11] loss: 0.551
[158,    11] loss: 0.549
[159,    11] loss: 0.562
[160,    11] loss: 0.560
[161,    11] loss: 0.550
[162,    11] loss: 0.548
[163,    11] loss: 0.548
[164,    11] loss: 0.554
[165,    11] loss: 0.558
[166,    11] loss: 0.561
[167,    11] loss: 0.552
[168,    11] loss: 0.553
[169,    11] loss: 0.548
[170,    11] loss: 0.545
[171,    11] loss: 0.543
[172,    11] loss: 0.544
[173,    11] loss: 0.580
[174,    11] loss: 0.550
[175,    11] loss: 0.562
[176,    11] loss: 0.555
[177,    11] loss: 0.551
[178,    11] loss: 0.543
[179,    11] loss: 0.553
[180,    11] loss: 0.557
[181,    11] loss: 0.553
[182,    11] loss: 0.560
[183,    11] loss: 0.554
[184,    11] loss: 0.561
Early stopping applied (best metric=0.3747868239879608)
Finished Training
Total time taken: 78.81028938293457
[1,     1] loss: 0.698
[2,    11] loss: 0.694
[3,    11] loss: 0.694
[4,    11] loss: 0.694
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.690
[8,    11] loss: 0.689
[9,    11] loss: 0.685
[10,    11] loss: 0.678
[11,    11] loss: 0.676
[12,    11] loss: 0.666
[13,    11] loss: 0.648
[14,    11] loss: 0.653
[15,    11] loss: 0.648
[16,    11] loss: 0.636
[17,    11] loss: 0.624
[18,    11] loss: 0.623
[19,    11] loss: 0.626
[20,    11] loss: 0.615
[21,    11] loss: 0.615
[22,    11] loss: 0.600
[23,    11] loss: 0.595
[24,    11] loss: 0.599
[25,    11] loss: 0.598
[26,    11] loss: 0.597
[27,    11] loss: 0.583
[28,    11] loss: 0.595
[29,    11] loss: 0.598
[30,    11] loss: 0.588
[31,    11] loss: 0.593
[32,    11] loss: 0.599
[33,    11] loss: 0.595
[34,    11] loss: 0.597
[35,    11] loss: 0.586
[36,    11] loss: 0.590
[37,    11] loss: 0.581
[38,    11] loss: 0.587
[39,    11] loss: 0.596
[40,    11] loss: 0.582
[41,    11] loss: 0.583
[42,    11] loss: 0.583
[43,    11] loss: 0.580
[44,    11] loss: 0.578
[45,    11] loss: 0.579
[46,    11] loss: 0.578
[47,    11] loss: 0.574
[48,    11] loss: 0.576
[49,    11] loss: 0.569
[50,    11] loss: 0.568
[51,    11] loss: 0.573
[52,    11] loss: 0.572
[53,    11] loss: 0.566
[54,    11] loss: 0.568
[55,    11] loss: 0.573
[56,    11] loss: 0.556
[57,    11] loss: 0.572
[58,    11] loss: 0.572
[59,    11] loss: 0.577
[60,    11] loss: 0.570
[61,    11] loss: 0.561
[62,    11] loss: 0.563
[63,    11] loss: 0.580
[64,    11] loss: 0.561
[65,    11] loss: 0.555
[66,    11] loss: 0.559
[67,    11] loss: 0.559
[68,    11] loss: 0.549
[69,    11] loss: 0.550
[70,    11] loss: 0.550
[71,    11] loss: 0.562
[72,    11] loss: 0.553
[73,    11] loss: 0.553
[74,    11] loss: 0.552
[75,    11] loss: 0.559
[76,    11] loss: 0.546
[77,    11] loss: 0.545
[78,    11] loss: 0.564
[79,    11] loss: 0.557
[80,    11] loss: 0.560
[81,    11] loss: 0.553
[82,    11] loss: 0.546
[83,    11] loss: 0.552
[84,    11] loss: 0.551
[85,    11] loss: 0.552
[86,    11] loss: 0.558
[87,    11] loss: 0.550
[88,    11] loss: 0.548
[89,    11] loss: 0.554
[90,    11] loss: 0.551
[91,    11] loss: 0.544
[92,    11] loss: 0.553
[93,    11] loss: 0.544
[94,    11] loss: 0.541
[95,    11] loss: 0.561
[96,    11] loss: 0.543
[97,    11] loss: 0.550
[98,    11] loss: 0.547
[99,    11] loss: 0.566
[100,    11] loss: 0.552
[101,    11] loss: 0.544
[102,    11] loss: 0.541
[103,    11] loss: 0.549
[104,    11] loss: 0.557
[105,    11] loss: 0.567
[106,    11] loss: 0.561
[107,    11] loss: 0.551
[108,    11] loss: 0.563
[109,    11] loss: 0.554
[110,    11] loss: 0.555
[111,    11] loss: 0.549
[112,    11] loss: 0.543
[113,    11] loss: 0.540
[114,    11] loss: 0.543
[115,    11] loss: 0.551
[116,    11] loss: 0.534
[117,    11] loss: 0.548
[118,    11] loss: 0.550
[119,    11] loss: 0.574
[120,    11] loss: 0.566
[121,    11] loss: 0.554
[122,    11] loss: 0.553
[123,    11] loss: 0.552
[124,    11] loss: 0.540
[125,    11] loss: 0.544
[126,    11] loss: 0.536
[127,    11] loss: 0.546
[128,    11] loss: 0.541
[129,    11] loss: 0.555
[130,    11] loss: 0.545
[131,    11] loss: 0.548
[132,    11] loss: 0.543
[133,    11] loss: 0.558
[134,    11] loss: 0.543
[135,    11] loss: 0.534
[136,    11] loss: 0.546
[137,    11] loss: 0.559
[138,    11] loss: 0.552
[139,    11] loss: 0.547
[140,    11] loss: 0.561
[141,    11] loss: 0.553
[142,    11] loss: 0.548
[143,    11] loss: 0.540
[144,    11] loss: 0.551
[145,    11] loss: 0.540
[146,    11] loss: 0.552
[147,    11] loss: 0.535
[148,    11] loss: 0.534
Early stopping applied (best metric=0.37328118085861206)
Finished Training
Total time taken: 67.11612105369568
[1,     1] loss: 0.694
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.691
[7,    11] loss: 0.691
[8,    11] loss: 0.689
[9,    11] loss: 0.686
[10,    11] loss: 0.678
[11,    11] loss: 0.666
[12,    11] loss: 0.658
[13,    11] loss: 0.648
[14,    11] loss: 0.641
[15,    11] loss: 0.635
[16,    11] loss: 0.618
[17,    11] loss: 0.612
[18,    11] loss: 0.613
[19,    11] loss: 0.625
[20,    11] loss: 0.615
[21,    11] loss: 0.600
[22,    11] loss: 0.601
[23,    11] loss: 0.602
[24,    11] loss: 0.596
[25,    11] loss: 0.601
[26,    11] loss: 0.592
[27,    11] loss: 0.596
[28,    11] loss: 0.590
[29,    11] loss: 0.600
[30,    11] loss: 0.591
[31,    11] loss: 0.581
[32,    11] loss: 0.592
[33,    11] loss: 0.594
[34,    11] loss: 0.601
[35,    11] loss: 0.589
[36,    11] loss: 0.573
[37,    11] loss: 0.576
[38,    11] loss: 0.579
[39,    11] loss: 0.583
[40,    11] loss: 0.558
[41,    11] loss: 0.584
[42,    11] loss: 0.575
[43,    11] loss: 0.566
[44,    11] loss: 0.570
[45,    11] loss: 0.573
[46,    11] loss: 0.569
[47,    11] loss: 0.563
[48,    11] loss: 0.568
[49,    11] loss: 0.567
[50,    11] loss: 0.570
[51,    11] loss: 0.573
[52,    11] loss: 0.566
[53,    11] loss: 0.563
[54,    11] loss: 0.567
[55,    11] loss: 0.556
[56,    11] loss: 0.570
[57,    11] loss: 0.569
[58,    11] loss: 0.552
[59,    11] loss: 0.564
[60,    11] loss: 0.552
[61,    11] loss: 0.547
[62,    11] loss: 0.553
[63,    11] loss: 0.555
[64,    11] loss: 0.567
[65,    11] loss: 0.550
[66,    11] loss: 0.545
[67,    11] loss: 0.554
[68,    11] loss: 0.552
[69,    11] loss: 0.545
[70,    11] loss: 0.547
[71,    11] loss: 0.545
[72,    11] loss: 0.542
[73,    11] loss: 0.544
[74,    11] loss: 0.564
[75,    11] loss: 0.547
[76,    11] loss: 0.549
[77,    11] loss: 0.537
[78,    11] loss: 0.551
[79,    11] loss: 0.534
[80,    11] loss: 0.551
[81,    11] loss: 0.553
[82,    11] loss: 0.541
[83,    11] loss: 0.551
[84,    11] loss: 0.554
[85,    11] loss: 0.546
[86,    11] loss: 0.552
[87,    11] loss: 0.541
[88,    11] loss: 0.556
[89,    11] loss: 0.555
[90,    11] loss: 0.545
[91,    11] loss: 0.549
[92,    11] loss: 0.550
[93,    11] loss: 0.544
[94,    11] loss: 0.540
[95,    11] loss: 0.549
[96,    11] loss: 0.552
[97,    11] loss: 0.563
[98,    11] loss: 0.553
[99,    11] loss: 0.573
[100,    11] loss: 0.548
[101,    11] loss: 0.540
[102,    11] loss: 0.542
[103,    11] loss: 0.551
[104,    11] loss: 0.532
[105,    11] loss: 0.546
[106,    11] loss: 0.546
[107,    11] loss: 0.551
[108,    11] loss: 0.540
[109,    11] loss: 0.557
[110,    11] loss: 0.547
[111,    11] loss: 0.545
[112,    11] loss: 0.568
[113,    11] loss: 0.550
[114,    11] loss: 0.543
[115,    11] loss: 0.545
[116,    11] loss: 0.542
[117,    11] loss: 0.542
[118,    11] loss: 0.554
[119,    11] loss: 0.544
[120,    11] loss: 0.555
[121,    11] loss: 0.548
[122,    11] loss: 0.555
[123,    11] loss: 0.540
[124,    11] loss: 0.530
[125,    11] loss: 0.542
[126,    11] loss: 0.535
[127,    11] loss: 0.550
[128,    11] loss: 0.547
[129,    11] loss: 0.554
[130,    11] loss: 0.553
[131,    11] loss: 0.546
[132,    11] loss: 0.560
[133,    11] loss: 0.575
[134,    11] loss: 0.542
[135,    11] loss: 0.539
[136,    11] loss: 0.539
[137,    11] loss: 0.544
[138,    11] loss: 0.539
[139,    11] loss: 0.540
[140,    11] loss: 0.563
[141,    11] loss: 0.554
[142,    11] loss: 0.554
[143,    11] loss: 0.559
[144,    11] loss: 0.549
[145,    11] loss: 0.545
[146,    11] loss: 0.537
[147,    11] loss: 0.541
[148,    11] loss: 0.545
[149,    11] loss: 0.537
[150,    11] loss: 0.549
[151,    11] loss: 0.551
[152,    11] loss: 0.549
[153,    11] loss: 0.539
[154,    11] loss: 0.543
[155,    11] loss: 0.538
[156,    11] loss: 0.547
[157,    11] loss: 0.540
[158,    11] loss: 0.536
[159,    11] loss: 0.541
[160,    11] loss: 0.545
[161,    11] loss: 0.543
[162,    11] loss: 0.545
[163,    11] loss: 0.536
[164,    11] loss: 0.542
[165,    11] loss: 0.536
[166,    11] loss: 0.539
[167,    11] loss: 0.538
[168,    11] loss: 0.549
[169,    11] loss: 0.556
[170,    11] loss: 0.552
[171,    11] loss: 0.550
[172,    11] loss: 0.545
[173,    11] loss: 0.538
[174,    11] loss: 0.543
[175,    11] loss: 0.543
[176,    11] loss: 0.538
[177,    11] loss: 0.544
[178,    11] loss: 0.539
Early stopping applied (best metric=0.3828655183315277)
Finished Training
Total time taken: 80.07039093971252
[1,     1] loss: 0.707
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.691
[7,    11] loss: 0.688
[8,    11] loss: 0.683
[9,    11] loss: 0.668
[10,    11] loss: 0.663
[11,    11] loss: 0.663
[12,    11] loss: 0.652
[13,    11] loss: 0.633
[14,    11] loss: 0.630
[15,    11] loss: 0.630
[16,    11] loss: 0.622
[17,    11] loss: 0.612
[18,    11] loss: 0.619
[19,    11] loss: 0.615
[20,    11] loss: 0.608
[21,    11] loss: 0.607
[22,    11] loss: 0.606
[23,    11] loss: 0.604
[24,    11] loss: 0.589
[25,    11] loss: 0.592
[26,    11] loss: 0.583
[27,    11] loss: 0.591
[28,    11] loss: 0.595
[29,    11] loss: 0.593
[30,    11] loss: 0.581
[31,    11] loss: 0.593
[32,    11] loss: 0.596
[33,    11] loss: 0.592
[34,    11] loss: 0.582
[35,    11] loss: 0.590
[36,    11] loss: 0.589
[37,    11] loss: 0.583
[38,    11] loss: 0.575
[39,    11] loss: 0.571
[40,    11] loss: 0.578
[41,    11] loss: 0.571
[42,    11] loss: 0.571
[43,    11] loss: 0.577
[44,    11] loss: 0.582
[45,    11] loss: 0.580
[46,    11] loss: 0.576
[47,    11] loss: 0.580
[48,    11] loss: 0.575
[49,    11] loss: 0.573
[50,    11] loss: 0.567
[51,    11] loss: 0.580
[52,    11] loss: 0.562
[53,    11] loss: 0.568
[54,    11] loss: 0.564
[55,    11] loss: 0.569
[56,    11] loss: 0.553
[57,    11] loss: 0.573
[58,    11] loss: 0.582
[59,    11] loss: 0.579
[60,    11] loss: 0.565
[61,    11] loss: 0.555
[62,    11] loss: 0.558
[63,    11] loss: 0.558
[64,    11] loss: 0.550
[65,    11] loss: 0.556
[66,    11] loss: 0.555
[67,    11] loss: 0.561
[68,    11] loss: 0.558
[69,    11] loss: 0.557
[70,    11] loss: 0.559
[71,    11] loss: 0.562
[72,    11] loss: 0.550
[73,    11] loss: 0.562
[74,    11] loss: 0.544
[75,    11] loss: 0.561
[76,    11] loss: 0.563
[77,    11] loss: 0.568
[78,    11] loss: 0.547
[79,    11] loss: 0.551
[80,    11] loss: 0.541
[81,    11] loss: 0.545
[82,    11] loss: 0.552
[83,    11] loss: 0.545
[84,    11] loss: 0.556
[85,    11] loss: 0.555
[86,    11] loss: 0.553
[87,    11] loss: 0.552
[88,    11] loss: 0.556
[89,    11] loss: 0.549
[90,    11] loss: 0.550
[91,    11] loss: 0.543
[92,    11] loss: 0.545
[93,    11] loss: 0.555
[94,    11] loss: 0.543
[95,    11] loss: 0.548
[96,    11] loss: 0.584
[97,    11] loss: 0.550
[98,    11] loss: 0.552
[99,    11] loss: 0.542
[100,    11] loss: 0.554
[101,    11] loss: 0.545
[102,    11] loss: 0.550
[103,    11] loss: 0.558
[104,    11] loss: 0.549
[105,    11] loss: 0.545
[106,    11] loss: 0.557
[107,    11] loss: 0.562
[108,    11] loss: 0.551
[109,    11] loss: 0.547
[110,    11] loss: 0.553
[111,    11] loss: 0.555
[112,    11] loss: 0.544
[113,    11] loss: 0.546
[114,    11] loss: 0.547
[115,    11] loss: 0.549
[116,    11] loss: 0.562
[117,    11] loss: 0.550
[118,    11] loss: 0.552
[119,    11] loss: 0.558
[120,    11] loss: 0.566
[121,    11] loss: 0.559
[122,    11] loss: 0.552
[123,    11] loss: 0.545
[124,    11] loss: 0.545
[125,    11] loss: 0.538
[126,    11] loss: 0.538
[127,    11] loss: 0.550
[128,    11] loss: 0.551
[129,    11] loss: 0.546
[130,    11] loss: 0.545
[131,    11] loss: 0.546
[132,    11] loss: 0.541
[133,    11] loss: 0.545
[134,    11] loss: 0.547
[135,    11] loss: 0.557
[136,    11] loss: 0.549
[137,    11] loss: 0.548
[138,    11] loss: 0.548
[139,    11] loss: 0.551
[140,    11] loss: 0.532
[141,    11] loss: 0.547
[142,    11] loss: 0.544
[143,    11] loss: 0.553
[144,    11] loss: 0.560
[145,    11] loss: 0.548
[146,    11] loss: 0.547
[147,    11] loss: 0.544
[148,    11] loss: 0.553
[149,    11] loss: 0.546
[150,    11] loss: 0.546
[151,    11] loss: 0.545
[152,    11] loss: 0.530
[153,    11] loss: 0.551
[154,    11] loss: 0.545
[155,    11] loss: 0.547
[156,    11] loss: 0.547
[157,    11] loss: 0.553
[158,    11] loss: 0.544
[159,    11] loss: 0.553
[160,    11] loss: 0.558
[161,    11] loss: 0.548
[162,    11] loss: 0.549
[163,    11] loss: 0.559
[164,    11] loss: 0.559
[165,    11] loss: 0.540
[166,    11] loss: 0.547
[167,    11] loss: 0.554
[168,    11] loss: 0.546
[169,    11] loss: 0.542
[170,    11] loss: 0.550
[171,    11] loss: 0.547
[172,    11] loss: 0.548
[173,    11] loss: 0.541
[174,    11] loss: 0.544
[175,    11] loss: 0.558
[176,    11] loss: 0.548
[177,    11] loss: 0.544
[178,    11] loss: 0.543
[179,    11] loss: 0.533
[180,    11] loss: 0.557
[181,    11] loss: 0.562
[182,    11] loss: 0.565
[183,    11] loss: 0.558
[184,    11] loss: 0.539
[185,    11] loss: 0.540
[186,    11] loss: 0.538
[187,    11] loss: 0.551
[188,    11] loss: 0.550
[189,    11] loss: 0.541
[190,    11] loss: 0.551
[191,    11] loss: 0.543
[192,    11] loss: 0.556
[193,    11] loss: 0.546
[194,    11] loss: 0.555
[195,    11] loss: 0.539
[196,    11] loss: 0.543
[197,    11] loss: 0.544
[198,    11] loss: 0.546
[199,    11] loss: 0.552
[200,    11] loss: 0.549
Finished Training
Total time taken: 97.83299160003662
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.693
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.691
[11,    11] loss: 0.689
[12,    11] loss: 0.687
[13,    11] loss: 0.676
[14,    11] loss: 0.662
[15,    11] loss: 0.656
[16,    11] loss: 0.654
[17,    11] loss: 0.645
[18,    11] loss: 0.623
[19,    11] loss: 0.627
[20,    11] loss: 0.620
[21,    11] loss: 0.616
[22,    11] loss: 0.604
[23,    11] loss: 0.605
[24,    11] loss: 0.605
[25,    11] loss: 0.605
[26,    11] loss: 0.594
[27,    11] loss: 0.596
[28,    11] loss: 0.610
[29,    11] loss: 0.592
[30,    11] loss: 0.590
[31,    11] loss: 0.592
[32,    11] loss: 0.585
[33,    11] loss: 0.578
[34,    11] loss: 0.585
[35,    11] loss: 0.581
[36,    11] loss: 0.583
[37,    11] loss: 0.594
[38,    11] loss: 0.578
[39,    11] loss: 0.584
[40,    11] loss: 0.585
[41,    11] loss: 0.582
[42,    11] loss: 0.588
[43,    11] loss: 0.581
[44,    11] loss: 0.582
[45,    11] loss: 0.582
[46,    11] loss: 0.578
[47,    11] loss: 0.575
[48,    11] loss: 0.566
[49,    11] loss: 0.564
[50,    11] loss: 0.580
[51,    11] loss: 0.576
[52,    11] loss: 0.568
[53,    11] loss: 0.568
[54,    11] loss: 0.573
[55,    11] loss: 0.564
[56,    11] loss: 0.577
[57,    11] loss: 0.569
[58,    11] loss: 0.566
[59,    11] loss: 0.560
[60,    11] loss: 0.561
[61,    11] loss: 0.564
[62,    11] loss: 0.559
[63,    11] loss: 0.566
[64,    11] loss: 0.568
[65,    11] loss: 0.570
[66,    11] loss: 0.577
[67,    11] loss: 0.554
[68,    11] loss: 0.561
[69,    11] loss: 0.555
[70,    11] loss: 0.577
[71,    11] loss: 0.551
[72,    11] loss: 0.560
[73,    11] loss: 0.570
[74,    11] loss: 0.560
[75,    11] loss: 0.560
[76,    11] loss: 0.561
[77,    11] loss: 0.553
[78,    11] loss: 0.558
[79,    11] loss: 0.558
[80,    11] loss: 0.564
[81,    11] loss: 0.547
[82,    11] loss: 0.549
[83,    11] loss: 0.563
[84,    11] loss: 0.543
[85,    11] loss: 0.553
[86,    11] loss: 0.550
[87,    11] loss: 0.549
[88,    11] loss: 0.556
[89,    11] loss: 0.558
[90,    11] loss: 0.550
[91,    11] loss: 0.553
[92,    11] loss: 0.552
[93,    11] loss: 0.553
[94,    11] loss: 0.554
[95,    11] loss: 0.549
[96,    11] loss: 0.561
[97,    11] loss: 0.558
[98,    11] loss: 0.556
[99,    11] loss: 0.562
[100,    11] loss: 0.553
[101,    11] loss: 0.560
[102,    11] loss: 0.554
[103,    11] loss: 0.554
[104,    11] loss: 0.554
[105,    11] loss: 0.552
[106,    11] loss: 0.580
[107,    11] loss: 0.563
[108,    11] loss: 0.559
[109,    11] loss: 0.554
[110,    11] loss: 0.545
[111,    11] loss: 0.551
[112,    11] loss: 0.544
[113,    11] loss: 0.563
[114,    11] loss: 0.568
[115,    11] loss: 0.555
[116,    11] loss: 0.544
[117,    11] loss: 0.554
[118,    11] loss: 0.558
[119,    11] loss: 0.549
[120,    11] loss: 0.533
[121,    11] loss: 0.552
[122,    11] loss: 0.555
[123,    11] loss: 0.554
[124,    11] loss: 0.561
[125,    11] loss: 0.554
[126,    11] loss: 0.549
[127,    11] loss: 0.546
[128,    11] loss: 0.548
[129,    11] loss: 0.549
[130,    11] loss: 0.550
[131,    11] loss: 0.536
[132,    11] loss: 0.539
[133,    11] loss: 0.549
[134,    11] loss: 0.547
[135,    11] loss: 0.543
[136,    11] loss: 0.540
[137,    11] loss: 0.555
[138,    11] loss: 0.542
[139,    11] loss: 0.536
[140,    11] loss: 0.561
[141,    11] loss: 0.555
[142,    11] loss: 0.551
[143,    11] loss: 0.542
[144,    11] loss: 0.563
[145,    11] loss: 0.555
[146,    11] loss: 0.550
[147,    11] loss: 0.552
[148,    11] loss: 0.539
[149,    11] loss: 0.549
[150,    11] loss: 0.544
[151,    11] loss: 0.545
[152,    11] loss: 0.549
[153,    11] loss: 0.537
[154,    11] loss: 0.539
[155,    11] loss: 0.560
[156,    11] loss: 0.551
[157,    11] loss: 0.551
[158,    11] loss: 0.553
[159,    11] loss: 0.539
[160,    11] loss: 0.546
[161,    11] loss: 0.543
[162,    11] loss: 0.573
[163,    11] loss: 0.559
[164,    11] loss: 0.550
[165,    11] loss: 0.554
[166,    11] loss: 0.535
[167,    11] loss: 0.544
[168,    11] loss: 0.541
[169,    11] loss: 0.556
[170,    11] loss: 0.563
[171,    11] loss: 0.546
[172,    11] loss: 0.560
[173,    11] loss: 0.536
[174,    11] loss: 0.546
[175,    11] loss: 0.542
[176,    11] loss: 0.546
[177,    11] loss: 0.551
[178,    11] loss: 0.552
[179,    11] loss: 0.544
[180,    11] loss: 0.550
[181,    11] loss: 0.555
[182,    11] loss: 0.558
[183,    11] loss: 0.543
[184,    11] loss: 0.557
Early stopping applied (best metric=0.36136505007743835)
Finished Training
Total time taken: 81.75360679626465
{'Sumoylation Validation Accuracy': 0.717092905084101, 'Sumoylation Validation Sensitivity': 0.7516321406151915, 'Sumoylation Validation Specificity': 0.7115679530431444, 'Sumoylation Validation Precision': 0.29493272619479133, 'Sumoylation AUC ROC': 0.806012092787925, 'Sumoylation AUC PR': 0.49376112142740824, 'Sumoylation MCC': 0.33482363960516703, 'Sumoylation F1': 0.42333385057429235, 'Validation Loss (Sumoylation)': 0.37201203107833863, 'Validation Loss (total)': 0.37201203107833863, 'TimeToTrain': 81.1166799545288}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011068224032064371,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 981480323,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 7.013985707757642}
[1,     1] loss: 0.692
[2,    11] loss: 0.694
[3,    11] loss: 0.693
[4,    11] loss: 0.694
[5,    11] loss: 0.694
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008064594153311323,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1495382740,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 20.42155892843536}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031349649487052494,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3022976570,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.4818340962036376}
[1,     1] loss: 0.693
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.691
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.691
[8,    11] loss: 0.690
[9,    11] loss: 0.690
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003544651261110829,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 967229160,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 12.676862376676139}
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.692
[9,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006250073951700909,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2261985673,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 8.985061005383368}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007398889001615392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2333904014,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 1.1474096021142022}
[1,     1] loss: 0.697
[2,    11] loss: 0.691
[3,    11] loss: 0.692
[4,    11] loss: 0.691
[5,    11] loss: 0.690
[6,    11] loss: 0.688
[7,    11] loss: 0.689
[8,    11] loss: 0.687
[9,    11] loss: 0.687
[10,    11] loss: 0.686
[11,    11] loss: 0.684
[12,    11] loss: 0.686
[13,    11] loss: 0.686
[14,    11] loss: 0.687
[15,    11] loss: 0.687
[16,    11] loss: 0.685
[17,    11] loss: 0.688
[18,    11] loss: 0.688
[19,    11] loss: 0.689
[20,    11] loss: 0.688
[21,    11] loss: 0.688
[22,    11] loss: 0.685
[23,    11] loss: 0.685
[24,    11] loss: 0.686
[25,    11] loss: 0.680
[26,    11] loss: 0.686
[27,    11] loss: 0.686
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021827995664337432,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1613375084,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.2827048341592997}
[1,     1] loss: 0.699
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009954664092733677,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3071348195,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 11.867354247621641}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007858750769819721,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1300363151,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 3.8918930358168855}
[1,     1] loss: 0.693
[2,    11] loss: 0.692
[3,    11] loss: 0.691
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027796472132755063,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3110054774,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 14.305297670437936}
[1,     1] loss: 0.705
[2,    11] loss: 0.693
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007289819787089508,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3585061722,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.259408853765035}
[1,     1] loss: 0.695
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.691
[6,    11] loss: 0.690
[7,    11] loss: 0.690
[8,    11] loss: 0.690
[9,    11] loss: 0.690
[10,    11] loss: 0.687
[11,    11] loss: 0.687
[12,    11] loss: 0.686
[13,    11] loss: 0.683
[14,    11] loss: 0.689
[15,    11] loss: 0.688
[16,    11] loss: 0.688
[17,    11] loss: 0.689
[18,    11] loss: 0.686
[19,    11] loss: 0.687
[20,    11] loss: 0.689
[21,    11] loss: 0.689
[22,    11] loss: 0.691
[23,    11] loss: 0.688
[24,    11] loss: 0.688
[25,    11] loss: 0.688
[26,    11] loss: 0.682
[27,    11] loss: 0.689
[28,    11] loss: 0.690
[29,    11] loss: 0.685
[30,    11] loss: 0.681
[31,    11] loss: 0.670
[32,    11] loss: 0.669
[33,    11] loss: 0.656
[34,    11] loss: 0.656
[35,    11] loss: 0.628
[36,    11] loss: 0.643
[37,    11] loss: 0.621
[38,    11] loss: 0.617
[39,    11] loss: 0.627
[40,    11] loss: 0.622
[41,    11] loss: 0.616
[42,    11] loss: 0.608
[43,    11] loss: 0.636
[44,    11] loss: 0.625
[45,    11] loss: 0.618
[46,    11] loss: 0.625
[47,    11] loss: 0.617
[48,    11] loss: 0.613
[49,    11] loss: 0.602
[50,    11] loss: 0.608
[51,    11] loss: 0.603
[52,    11] loss: 0.618
[53,    11] loss: 0.624
[54,    11] loss: 0.612
[55,    11] loss: 0.604
[56,    11] loss: 0.612
[57,    11] loss: 0.600
[58,    11] loss: 0.625
[59,    11] loss: 0.606
[60,    11] loss: 0.604
[61,    11] loss: 0.605
[62,    11] loss: 0.605
[63,    11] loss: 0.604
[64,    11] loss: 0.607
[65,    11] loss: 0.612
[66,    11] loss: 0.610
[67,    11] loss: 0.598
[68,    11] loss: 0.603
[69,    11] loss: 0.628
[70,    11] loss: 0.621
[71,    11] loss: 0.606
[72,    11] loss: 0.599
[73,    11] loss: 0.593
[74,    11] loss: 0.613
[75,    11] loss: 0.609
[76,    11] loss: 0.588
[77,    11] loss: 0.602
[78,    11] loss: 0.611
[79,    11] loss: 0.595
[80,    11] loss: 0.616
[81,    11] loss: 0.602
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00889631708090933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 599728920,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 6.826754839596257}
[1,     1] loss: 0.694
[2,    11] loss: 0.692
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034698216784314834,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3284874116,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.057522630514296}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00999465448753978,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1623940498,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 16.382892955540278}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00014103733373331583,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3761315422,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 2.051395825272804}
[1,     1] loss: 0.691
[2,    11] loss: 0.693
[3,    11] loss: 0.694
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004513623683715337,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 4168765962,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 11.674556534051515}
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00048195043762843374,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 4212771768,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 14.590681203161658}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005508443835470838,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3562078748,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.83233271743574}
[1,     1] loss: 0.698
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00487434771639521,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 40258580,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.090636362724787}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008616432550212933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 616241227,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 13.980935681258718}
[1,     1] loss: 0.698
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008392346105185335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 669574158,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 24.858347754043947}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020699277403673643,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2723148473,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 6.270364826566683}
[1,     1] loss: 0.698
[2,    11] loss: 0.692
[3,    11] loss: 0.693
[4,    11] loss: 0.692
[5,    11] loss: 0.691
[6,    11] loss: 0.690
[7,    11] loss: 0.682
[8,    11] loss: 0.669
[9,    11] loss: 0.663
[10,    11] loss: 0.638
[11,    11] loss: 0.651
[12,    11] loss: 0.625
[13,    11] loss: 0.598
[14,    11] loss: 0.615
[15,    11] loss: 0.619
[16,    11] loss: 0.603
[17,    11] loss: 0.610
[18,    11] loss: 0.596
[19,    11] loss: 0.599
[20,    11] loss: 0.585
[21,    11] loss: 0.603
[22,    11] loss: 0.602
[23,    11] loss: 0.591
[24,    11] loss: 0.595
[25,    11] loss: 0.590
[26,    11] loss: 0.589
[27,    11] loss: 0.588
[28,    11] loss: 0.594
[29,    11] loss: 0.582
[30,    11] loss: 0.593
[31,    11] loss: 0.588
[32,    11] loss: 0.585
[33,    11] loss: 0.589
[34,    11] loss: 0.587
[35,    11] loss: 0.588
[36,    11] loss: 0.573
[37,    11] loss: 0.583
[38,    11] loss: 0.574
[39,    11] loss: 0.580
[40,    11] loss: 0.581
[41,    11] loss: 0.644
[42,    11] loss: 0.600
[43,    11] loss: 0.596
[44,    11] loss: 0.585
[45,    11] loss: 0.583
[46,    11] loss: 0.602
[47,    11] loss: 0.590
[48,    11] loss: 0.584
[49,    11] loss: 0.594
[50,    11] loss: 0.596
[51,    11] loss: 0.594
[52,    11] loss: 0.591
[53,    11] loss: 0.587
[54,    11] loss: 0.588
[55,    11] loss: 0.593
[56,    11] loss: 0.592
[57,    11] loss: 0.603
[58,    11] loss: 0.587
[59,    11] loss: 0.593
[60,    11] loss: 0.593
[61,    11] loss: 0.587
[62,    11] loss: 0.602
[63,    11] loss: 0.592
[64,    11] loss: 0.589
[65,    11] loss: 0.583
[66,    11] loss: 0.605
[67,    11] loss: 0.595
[68,    11] loss: 0.594
[69,    11] loss: 0.591
[70,    11] loss: 0.588
[71,    11] loss: 0.597
[72,    11] loss: 0.594
[73,    11] loss: 0.586
[74,    11] loss: 0.598
[75,    11] loss: 0.580
[76,    11] loss: 0.586
[77,    11] loss: 0.605
[78,    11] loss: 0.593
[79,    11] loss: 0.587
Early stopping applied (best metric=0.3949979543685913)
Finished Training
Total time taken: 31.729593753814697
[1,     1] loss: 0.698
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.691
[5,    11] loss: 0.691
[6,    11] loss: 0.691
[7,    11] loss: 0.690
[8,    11] loss: 0.684
[9,    11] loss: 0.675
[10,    11] loss: 0.667
[11,    11] loss: 0.650
[12,    11] loss: 0.625
[13,    11] loss: 0.624
[14,    11] loss: 0.610
[15,    11] loss: 0.609
[16,    11] loss: 0.594
[17,    11] loss: 0.604
[18,    11] loss: 0.605
[19,    11] loss: 0.597
[20,    11] loss: 0.591
[21,    11] loss: 0.583
[22,    11] loss: 0.582
[23,    11] loss: 0.582
[24,    11] loss: 0.589
[25,    11] loss: 0.609
[26,    11] loss: 0.588
[27,    11] loss: 0.589
[28,    11] loss: 0.578
[29,    11] loss: 0.582
[30,    11] loss: 0.578
[31,    11] loss: 0.595
[32,    11] loss: 0.581
[33,    11] loss: 0.578
[34,    11] loss: 0.567
[35,    11] loss: 0.583
[36,    11] loss: 0.608
[37,    11] loss: 0.592
[38,    11] loss: 0.590
[39,    11] loss: 0.582
[40,    11] loss: 0.581
[41,    11] loss: 0.577
[42,    11] loss: 0.598
[43,    11] loss: 0.599
[44,    11] loss: 0.590
[45,    11] loss: 0.599
[46,    11] loss: 0.585
[47,    11] loss: 0.584
[48,    11] loss: 0.588
[49,    11] loss: 0.584
[50,    11] loss: 0.602
[51,    11] loss: 0.594
[52,    11] loss: 0.585
[53,    11] loss: 0.595
[54,    11] loss: 0.589
[55,    11] loss: 0.585
[56,    11] loss: 0.599
[57,    11] loss: 0.591
[58,    11] loss: 0.592
[59,    11] loss: 0.572
[60,    11] loss: 0.586
[61,    11] loss: 0.581
[62,    11] loss: 0.586
[63,    11] loss: 0.591
[64,    11] loss: 0.583
[65,    11] loss: 0.584
[66,    11] loss: 0.578
[67,    11] loss: 0.588
[68,    11] loss: 0.586
[69,    11] loss: 0.585
[70,    11] loss: 0.591
[71,    11] loss: 0.602
[72,    11] loss: 0.583
[73,    11] loss: 0.582
[74,    11] loss: 0.580
[75,    11] loss: 0.583
[76,    11] loss: 0.590
[77,    11] loss: 0.589
[78,    11] loss: 0.574
[79,    11] loss: 0.585
[80,    11] loss: 0.598
[81,    11] loss: 0.588
[82,    11] loss: 0.578
[83,    11] loss: 0.584
[84,    11] loss: 0.588
[85,    11] loss: 0.588
[86,    11] loss: 0.603
[87,    11] loss: 0.591
[88,    11] loss: 0.589
[89,    11] loss: 0.581
[90,    11] loss: 0.591
[91,    11] loss: 0.586
[92,    11] loss: 0.584
[93,    11] loss: 0.579
[94,    11] loss: 0.583
[95,    11] loss: 0.576
[96,    11] loss: 0.576
[97,    11] loss: 0.584
[98,    11] loss: 0.586
[99,    11] loss: 0.593
[100,    11] loss: 0.584
[101,    11] loss: 0.578
[102,    11] loss: 0.582
[103,    11] loss: 0.582
[104,    11] loss: 0.596
[105,    11] loss: 0.588
[106,    11] loss: 0.586
[107,    11] loss: 0.581
[108,    11] loss: 0.585
[109,    11] loss: 0.580
[110,    11] loss: 0.580
[111,    11] loss: 0.595
[112,    11] loss: 0.585
[113,    11] loss: 0.595
[114,    11] loss: 0.591
[115,    11] loss: 0.595
Early stopping applied (best metric=0.3889508545398712)
Finished Training
Total time taken: 46.463367223739624
[1,     1] loss: 0.695
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.691
[6,    11] loss: 0.690
[7,    11] loss: 0.684
[8,    11] loss: 0.666
[9,    11] loss: 0.664
[10,    11] loss: 0.647
[11,    11] loss: 0.623
[12,    11] loss: 0.619
[13,    11] loss: 0.610
[14,    11] loss: 0.614
[15,    11] loss: 0.602
[16,    11] loss: 0.602
[17,    11] loss: 0.599
[18,    11] loss: 0.599
[19,    11] loss: 0.600
[20,    11] loss: 0.609
[21,    11] loss: 0.607
[22,    11] loss: 0.592
[23,    11] loss: 0.587
[24,    11] loss: 0.606
[25,    11] loss: 0.581
[26,    11] loss: 0.602
[27,    11] loss: 0.582
[28,    11] loss: 0.604
[29,    11] loss: 0.605
[30,    11] loss: 0.593
[31,    11] loss: 0.590
[32,    11] loss: 0.589
[33,    11] loss: 0.594
[34,    11] loss: 0.590
[35,    11] loss: 0.601
[36,    11] loss: 0.597
[37,    11] loss: 0.587
[38,    11] loss: 0.583
[39,    11] loss: 0.593
[40,    11] loss: 0.596
[41,    11] loss: 0.611
[42,    11] loss: 0.593
[43,    11] loss: 0.582
[44,    11] loss: 0.598
[45,    11] loss: 0.589
[46,    11] loss: 0.582
[47,    11] loss: 0.583
[48,    11] loss: 0.594
[49,    11] loss: 0.592
[50,    11] loss: 0.575
[51,    11] loss: 0.587
[52,    11] loss: 0.588
[53,    11] loss: 0.601
[54,    11] loss: 0.586
[55,    11] loss: 0.592
[56,    11] loss: 0.606
[57,    11] loss: 0.586
[58,    11] loss: 0.584
[59,    11] loss: 0.586
[60,    11] loss: 0.603
[61,    11] loss: 0.596
[62,    11] loss: 0.592
[63,    11] loss: 0.594
[64,    11] loss: 0.589
[65,    11] loss: 0.589
[66,    11] loss: 0.593
[67,    11] loss: 0.588
[68,    11] loss: 0.632
[69,    11] loss: 0.600
[70,    11] loss: 0.598
[71,    11] loss: 0.597
[72,    11] loss: 0.591
[73,    11] loss: 0.596
[74,    11] loss: 0.601
[75,    11] loss: 0.593
[76,    11] loss: 0.587
[77,    11] loss: 0.589
[78,    11] loss: 0.596
[79,    11] loss: 0.600
[80,    11] loss: 0.592
[81,    11] loss: 0.603
[82,    11] loss: 0.591
[83,    11] loss: 0.603
[84,    11] loss: 0.608
[85,    11] loss: 0.599
[86,    11] loss: 0.587
[87,    11] loss: 0.594
[88,    11] loss: 0.603
[89,    11] loss: 0.591
[90,    11] loss: 0.592
[91,    11] loss: 0.602
[92,    11] loss: 0.603
[93,    11] loss: 0.608
[94,    11] loss: 0.608
[95,    11] loss: 0.602
[96,    11] loss: 0.592
[97,    11] loss: 0.591
[98,    11] loss: 0.594
[99,    11] loss: 0.599
[100,    11] loss: 0.597
Early stopping applied (best metric=0.39252766966819763)
Finished Training
Total time taken: 40.764525413513184
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.693
[6,    11] loss: 0.692
[7,    11] loss: 0.690
[8,    11] loss: 0.683
[9,    11] loss: 0.676
[10,    11] loss: 0.673
[11,    11] loss: 0.660
[12,    11] loss: 0.629
[13,    11] loss: 0.622
[14,    11] loss: 0.614
[15,    11] loss: 0.612
[16,    11] loss: 0.597
[17,    11] loss: 0.609
[18,    11] loss: 0.600
[19,    11] loss: 0.603
[20,    11] loss: 0.592
[21,    11] loss: 0.597
[22,    11] loss: 0.593
[23,    11] loss: 0.595
[24,    11] loss: 0.596
[25,    11] loss: 0.590
[26,    11] loss: 0.594
[27,    11] loss: 0.575
[28,    11] loss: 0.585
[29,    11] loss: 0.600
[30,    11] loss: 0.589
[31,    11] loss: 0.590
[32,    11] loss: 0.576
[33,    11] loss: 0.585
[34,    11] loss: 0.587
[35,    11] loss: 0.580
[36,    11] loss: 0.590
[37,    11] loss: 0.590
[38,    11] loss: 0.584
[39,    11] loss: 0.590
[40,    11] loss: 0.595
[41,    11] loss: 0.591
[42,    11] loss: 0.583
[43,    11] loss: 0.600
[44,    11] loss: 0.602
[45,    11] loss: 0.591
[46,    11] loss: 0.586
[47,    11] loss: 0.593
[48,    11] loss: 0.595
[49,    11] loss: 0.583
[50,    11] loss: 0.594
[51,    11] loss: 0.593
[52,    11] loss: 0.586
[53,    11] loss: 0.587
[54,    11] loss: 0.574
[55,    11] loss: 0.578
[56,    11] loss: 0.599
[57,    11] loss: 0.596
[58,    11] loss: 0.599
[59,    11] loss: 0.602
[60,    11] loss: 0.594
[61,    11] loss: 0.605
[62,    11] loss: 0.593
[63,    11] loss: 0.621
[64,    11] loss: 0.600
[65,    11] loss: 0.601
[66,    11] loss: 0.584
[67,    11] loss: 0.602
[68,    11] loss: 0.596
[69,    11] loss: 0.592
[70,    11] loss: 0.591
[71,    11] loss: 0.602
[72,    11] loss: 0.600
[73,    11] loss: 0.581
[74,    11] loss: 0.585
[75,    11] loss: 0.592
[76,    11] loss: 0.598
[77,    11] loss: 0.607
[78,    11] loss: 0.607
[79,    11] loss: 0.590
[80,    11] loss: 0.594
[81,    11] loss: 0.590
[82,    11] loss: 0.587
[83,    11] loss: 0.586
[84,    11] loss: 0.600
[85,    11] loss: 0.606
[86,    11] loss: 0.597
[87,    11] loss: 0.588
[88,    11] loss: 0.603
[89,    11] loss: 0.600
[90,    11] loss: 0.598
[91,    11] loss: 0.590
[92,    11] loss: 0.591
Early stopping applied (best metric=0.3998672366142273)
Finished Training
Total time taken: 38.34892392158508
[1,     1] loss: 0.692
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.692
[6,    11] loss: 0.693
[7,    11] loss: 0.692
[8,    11] loss: 0.690
[9,    11] loss: 0.681
[10,    11] loss: 0.676
[11,    11] loss: 0.670
[12,    11] loss: 0.643
[13,    11] loss: 0.637
[14,    11] loss: 0.612
[15,    11] loss: 0.613
[16,    11] loss: 0.605
[17,    11] loss: 0.594
[18,    11] loss: 0.596
[19,    11] loss: 0.613
[20,    11] loss: 0.600
[21,    11] loss: 0.586
[22,    11] loss: 0.595
[23,    11] loss: 0.570
[24,    11] loss: 0.598
[25,    11] loss: 0.596
[26,    11] loss: 0.585
[27,    11] loss: 0.587
[28,    11] loss: 0.584
[29,    11] loss: 0.597
[30,    11] loss: 0.613
[31,    11] loss: 0.604
[32,    11] loss: 0.596
[33,    11] loss: 0.597
[34,    11] loss: 0.582
[35,    11] loss: 0.585
[36,    11] loss: 0.582
[37,    11] loss: 0.590
[38,    11] loss: 0.591
[39,    11] loss: 0.592
[40,    11] loss: 0.592
[41,    11] loss: 0.584
[42,    11] loss: 0.588
[43,    11] loss: 0.602
[44,    11] loss: 0.592
[45,    11] loss: 0.586
[46,    11] loss: 0.589
[47,    11] loss: 0.581
[48,    11] loss: 0.596
[49,    11] loss: 0.596
[50,    11] loss: 0.594
[51,    11] loss: 0.587
[52,    11] loss: 0.583
[53,    11] loss: 0.591
[54,    11] loss: 0.587
[55,    11] loss: 0.614
[56,    11] loss: 0.594
[57,    11] loss: 0.590
[58,    11] loss: 0.587
[59,    11] loss: 0.598
[60,    11] loss: 0.603
[61,    11] loss: 0.594
[62,    11] loss: 0.584
[63,    11] loss: 0.584
[64,    11] loss: 0.602
[65,    11] loss: 0.583
[66,    11] loss: 0.592
[67,    11] loss: 0.608
[68,    11] loss: 0.585
[69,    11] loss: 0.590
[70,    11] loss: 0.583
[71,    11] loss: 0.590
[72,    11] loss: 0.610
[73,    11] loss: 0.585
[74,    11] loss: 0.590
[75,    11] loss: 0.594
[76,    11] loss: 0.579
[77,    11] loss: 0.610
[78,    11] loss: 0.587
[79,    11] loss: 0.595
[80,    11] loss: 0.595
[81,    11] loss: 0.592
[82,    11] loss: 0.603
[83,    11] loss: 0.591
[84,    11] loss: 0.587
[85,    11] loss: 0.584
[86,    11] loss: 0.585
[87,    11] loss: 0.602
[88,    11] loss: 0.584
[89,    11] loss: 0.609
[90,    11] loss: 0.592
[91,    11] loss: 0.596
[92,    11] loss: 0.594
[93,    11] loss: 0.598
[94,    11] loss: 0.588
[95,    11] loss: 0.593
[96,    11] loss: 0.610
Early stopping applied (best metric=0.39124631881713867)
Finished Training
Total time taken: 38.95081305503845
{'Sumoylation Validation Accuracy': 0.6519648741429128, 'Sumoylation Validation Sensitivity': 0.7528600506001636, 'Sumoylation Validation Specificity': 0.6358191210217871, 'Sumoylation Validation Precision': 0.24957436455883894, 'Sumoylation AUC ROC': 0.7744364046894399, 'Sumoylation AUC PR': 0.4400439121587271, 'Sumoylation MCC': 0.2724070452868088, 'Sumoylation F1': 0.37457755740767684, 'Validation Loss (Sumoylation)': 0.3935180068016052, 'Validation Loss (total)': 0.3935180068016052, 'TimeToTrain': 39.25144467353821}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005459823428334474,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2954801595,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 1.4682411390684769}
[1,     1] loss: 0.693
[2,    11] loss: 0.691
[3,    11] loss: 0.690
[4,    11] loss: 0.690
[5,    11] loss: 0.689
[6,    11] loss: 0.690
[7,    11] loss: 0.689
[8,    11] loss: 0.687
[9,    11] loss: 0.687
[10,    11] loss: 0.688
[11,    11] loss: 0.689
[12,    11] loss: 0.687
[13,    11] loss: 0.688
[14,    11] loss: 0.687
[15,    11] loss: 0.688
[16,    11] loss: 0.688
[17,    11] loss: 0.689
[18,    11] loss: 0.686
[19,    11] loss: 0.687
[20,    11] loss: 0.677
[21,    11] loss: 0.667
[22,    11] loss: 0.651
[23,    11] loss: 0.628
[24,    11] loss: 0.613
[25,    11] loss: 0.627
[26,    11] loss: 0.619
[27,    11] loss: 0.611
[28,    11] loss: 0.603
[29,    11] loss: 0.596
[30,    11] loss: 0.595
[31,    11] loss: 0.590
[32,    11] loss: 0.603
[33,    11] loss: 0.590
[34,    11] loss: 0.609
[35,    11] loss: 0.595
[36,    11] loss: 0.589
[37,    11] loss: 0.594
[38,    11] loss: 0.599
[39,    11] loss: 0.590
[40,    11] loss: 0.598
[41,    11] loss: 0.590
[42,    11] loss: 0.590
[43,    11] loss: 0.583
[44,    11] loss: 0.596
[45,    11] loss: 0.593
[46,    11] loss: 0.581
[47,    11] loss: 0.579
[48,    11] loss: 0.588
[49,    11] loss: 0.592
[50,    11] loss: 0.585
[51,    11] loss: 0.585
[52,    11] loss: 0.579
[53,    11] loss: 0.585
[54,    11] loss: 0.576
[55,    11] loss: 0.587
[56,    11] loss: 0.578
[57,    11] loss: 0.583
[58,    11] loss: 0.595
[59,    11] loss: 0.573
[60,    11] loss: 0.558
[61,    11] loss: 0.563
[62,    11] loss: 0.582
[63,    11] loss: 0.593
[64,    11] loss: 0.578
[65,    11] loss: 0.592
[66,    11] loss: 0.565
[67,    11] loss: 0.572
[68,    11] loss: 0.571
[69,    11] loss: 0.563
[70,    11] loss: 0.574
[71,    11] loss: 0.580
[72,    11] loss: 0.574
[73,    11] loss: 0.571
[74,    11] loss: 0.571
[75,    11] loss: 0.585
[76,    11] loss: 0.574
[77,    11] loss: 0.574
[78,    11] loss: 0.583
[79,    11] loss: 0.564
[80,    11] loss: 0.571
[81,    11] loss: 0.564
[82,    11] loss: 0.578
[83,    11] loss: 0.581
[84,    11] loss: 0.584
[85,    11] loss: 0.571
[86,    11] loss: 0.564
[87,    11] loss: 0.565
[88,    11] loss: 0.573
[89,    11] loss: 0.577
[90,    11] loss: 0.577
[91,    11] loss: 0.577
[92,    11] loss: 0.578
[93,    11] loss: 0.569
[94,    11] loss: 0.574
[95,    11] loss: 0.552
[96,    11] loss: 0.576
[97,    11] loss: 0.577
[98,    11] loss: 0.596
[99,    11] loss: 0.568
[100,    11] loss: 0.568
[101,    11] loss: 0.567
[102,    11] loss: 0.558
[103,    11] loss: 0.579
[104,    11] loss: 0.570
[105,    11] loss: 0.566
[106,    11] loss: 0.564
[107,    11] loss: 0.575
[108,    11] loss: 0.579
[109,    11] loss: 0.560
[110,    11] loss: 0.574
[111,    11] loss: 0.575
[112,    11] loss: 0.577
[113,    11] loss: 0.579
[114,    11] loss: 0.561
[115,    11] loss: 0.572
[116,    11] loss: 0.575
[117,    11] loss: 0.568
[118,    11] loss: 0.579
[119,    11] loss: 0.560
[120,    11] loss: 0.561
[121,    11] loss: 0.579
[122,    11] loss: 0.574
[123,    11] loss: 0.577
[124,    11] loss: 0.567
[125,    11] loss: 0.561
[126,    11] loss: 0.571
[127,    11] loss: 0.583
[128,    11] loss: 0.577
[129,    11] loss: 0.565
[130,    11] loss: 0.559
[131,    11] loss: 0.574
[132,    11] loss: 0.576
[133,    11] loss: 0.567
[134,    11] loss: 0.555
[135,    11] loss: 0.565
[136,    11] loss: 0.561
[137,    11] loss: 0.570
[138,    11] loss: 0.567
[139,    11] loss: 0.563
[140,    11] loss: 0.565
[141,    11] loss: 0.568
[142,    11] loss: 0.573
[143,    11] loss: 0.573
[144,    11] loss: 0.578
[145,    11] loss: 0.570
[146,    11] loss: 0.580
[147,    11] loss: 0.569
[148,    11] loss: 0.575
[149,    11] loss: 0.575
[150,    11] loss: 0.594
[151,    11] loss: 0.574
[152,    11] loss: 0.564
[153,    11] loss: 0.570
[154,    11] loss: 0.576
[155,    11] loss: 0.564
[156,    11] loss: 0.563
[157,    11] loss: 0.567
[158,    11] loss: 0.566
[159,    11] loss: 0.570
[160,    11] loss: 0.566
[161,    11] loss: 0.573
[162,    11] loss: 0.565
[163,    11] loss: 0.569
[164,    11] loss: 0.566
[165,    11] loss: 0.572
[166,    11] loss: 0.578
[167,    11] loss: 0.567
[168,    11] loss: 0.572
[169,    11] loss: 0.566
[170,    11] loss: 0.557
[171,    11] loss: 0.550
[172,    11] loss: 0.574
[173,    11] loss: 0.596
[174,    11] loss: 0.561
[175,    11] loss: 0.572
[176,    11] loss: 0.572
[177,    11] loss: 0.571
[178,    11] loss: 0.572
[179,    11] loss: 0.568
[180,    11] loss: 0.570
[181,    11] loss: 0.574
[182,    11] loss: 0.582
[183,    11] loss: 0.567
[184,    11] loss: 0.594
[185,    11] loss: 0.560
[186,    11] loss: 0.552
[187,    11] loss: 0.578
[188,    11] loss: 0.569
[189,    11] loss: 0.568
[190,    11] loss: 0.579
[191,    11] loss: 0.564
[192,    11] loss: 0.558
[193,    11] loss: 0.563
[194,    11] loss: 0.582
[195,    11] loss: 0.577
[196,    11] loss: 0.589
[197,    11] loss: 0.585
[198,    11] loss: 0.581
[199,    11] loss: 0.569
[200,    11] loss: 0.581
Finished Training
Total time taken: 81.06006574630737
[1,     1] loss: 0.691
[2,    11] loss: 0.691
[3,    11] loss: 0.691
[4,    11] loss: 0.689
[5,    11] loss: 0.691
[6,    11] loss: 0.689
[7,    11] loss: 0.688
[8,    11] loss: 0.687
[9,    11] loss: 0.688
[10,    11] loss: 0.689
[11,    11] loss: 0.687
[12,    11] loss: 0.687
[13,    11] loss: 0.687
[14,    11] loss: 0.684
[15,    11] loss: 0.685
[16,    11] loss: 0.687
[17,    11] loss: 0.686
[18,    11] loss: 0.686
[19,    11] loss: 0.670
[20,    11] loss: 0.669
[21,    11] loss: 0.640
[22,    11] loss: 0.625
[23,    11] loss: 0.623
[24,    11] loss: 0.611
[25,    11] loss: 0.624
[26,    11] loss: 0.604
[27,    11] loss: 0.602
[28,    11] loss: 0.598
[29,    11] loss: 0.603
[30,    11] loss: 0.594
[31,    11] loss: 0.611
[32,    11] loss: 0.596
[33,    11] loss: 0.574
[34,    11] loss: 0.576
[35,    11] loss: 0.589
[36,    11] loss: 0.585
[37,    11] loss: 0.601
[38,    11] loss: 0.586
[39,    11] loss: 0.571
[40,    11] loss: 0.576
[41,    11] loss: 0.588
[42,    11] loss: 0.569
[43,    11] loss: 0.573
[44,    11] loss: 0.578
[45,    11] loss: 0.578
[46,    11] loss: 0.575
[47,    11] loss: 0.582
[48,    11] loss: 0.587
[49,    11] loss: 0.579
[50,    11] loss: 0.569
[51,    11] loss: 0.567
[52,    11] loss: 0.564
[53,    11] loss: 0.564
[54,    11] loss: 0.564
[55,    11] loss: 0.565
[56,    11] loss: 0.567
[57,    11] loss: 0.567
[58,    11] loss: 0.567
[59,    11] loss: 0.565
[60,    11] loss: 0.575
[61,    11] loss: 0.572
[62,    11] loss: 0.560
[63,    11] loss: 0.553
[64,    11] loss: 0.574
[65,    11] loss: 0.565
[66,    11] loss: 0.578
[67,    11] loss: 0.573
[68,    11] loss: 0.562
[69,    11] loss: 0.592
[70,    11] loss: 0.572
[71,    11] loss: 0.576
[72,    11] loss: 0.566
[73,    11] loss: 0.571
[74,    11] loss: 0.573
[75,    11] loss: 0.582
[76,    11] loss: 0.580
[77,    11] loss: 0.584
[78,    11] loss: 0.566
[79,    11] loss: 0.563
[80,    11] loss: 0.577
[81,    11] loss: 0.574
[82,    11] loss: 0.588
[83,    11] loss: 0.573
[84,    11] loss: 0.575
[85,    11] loss: 0.555
[86,    11] loss: 0.560
[87,    11] loss: 0.563
[88,    11] loss: 0.564
[89,    11] loss: 0.563
[90,    11] loss: 0.580
[91,    11] loss: 0.562
[92,    11] loss: 0.555
[93,    11] loss: 0.570
[94,    11] loss: 0.588
[95,    11] loss: 0.581
[96,    11] loss: 0.573
[97,    11] loss: 0.581
[98,    11] loss: 0.563
[99,    11] loss: 0.566
[100,    11] loss: 0.561
[101,    11] loss: 0.570
[102,    11] loss: 0.572
[103,    11] loss: 0.567
[104,    11] loss: 0.573
[105,    11] loss: 0.561
[106,    11] loss: 0.566
[107,    11] loss: 0.570
[108,    11] loss: 0.567
[109,    11] loss: 0.574
[110,    11] loss: 0.571
[111,    11] loss: 0.568
[112,    11] loss: 0.571
[113,    11] loss: 0.557
[114,    11] loss: 0.566
[115,    11] loss: 0.572
[116,    11] loss: 0.572
[117,    11] loss: 0.566
[118,    11] loss: 0.557
[119,    11] loss: 0.553
[120,    11] loss: 0.570
[121,    11] loss: 0.580
[122,    11] loss: 0.575
[123,    11] loss: 0.558
[124,    11] loss: 0.565
[125,    11] loss: 0.569
[126,    11] loss: 0.557
[127,    11] loss: 0.564
[128,    11] loss: 0.555
[129,    11] loss: 0.561
[130,    11] loss: 0.572
[131,    11] loss: 0.578
[132,    11] loss: 0.570
[133,    11] loss: 0.560
[134,    11] loss: 0.561
[135,    11] loss: 0.578
[136,    11] loss: 0.570
[137,    11] loss: 0.564
[138,    11] loss: 0.566
[139,    11] loss: 0.561
[140,    11] loss: 0.562
[141,    11] loss: 0.575
[142,    11] loss: 0.569
[143,    11] loss: 0.565
[144,    11] loss: 0.554
[145,    11] loss: 0.573
[146,    11] loss: 0.562
Early stopping applied (best metric=0.37638625502586365)
Finished Training
Total time taken: 58.81129574775696
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.691
[5,    11] loss: 0.690
[6,    11] loss: 0.691
[7,    11] loss: 0.689
[8,    11] loss: 0.689
[9,    11] loss: 0.690
[10,    11] loss: 0.687
[11,    11] loss: 0.688
[12,    11] loss: 0.688
[13,    11] loss: 0.686
[14,    11] loss: 0.688
[15,    11] loss: 0.685
[16,    11] loss: 0.685
[17,    11] loss: 0.686
[18,    11] loss: 0.689
[19,    11] loss: 0.685
[20,    11] loss: 0.675
[21,    11] loss: 0.657
[22,    11] loss: 0.645
[23,    11] loss: 0.637
[24,    11] loss: 0.612
[25,    11] loss: 0.610
[26,    11] loss: 0.614
[27,    11] loss: 0.615
[28,    11] loss: 0.608
[29,    11] loss: 0.600
[30,    11] loss: 0.599
[31,    11] loss: 0.592
[32,    11] loss: 0.591
[33,    11] loss: 0.601
[34,    11] loss: 0.593
[35,    11] loss: 0.581
[36,    11] loss: 0.576
[37,    11] loss: 0.581
[38,    11] loss: 0.574
[39,    11] loss: 0.596
[40,    11] loss: 0.580
[41,    11] loss: 0.602
[42,    11] loss: 0.572
[43,    11] loss: 0.582
[44,    11] loss: 0.580
[45,    11] loss: 0.578
[46,    11] loss: 0.576
[47,    11] loss: 0.575
[48,    11] loss: 0.572
[49,    11] loss: 0.582
[50,    11] loss: 0.582
[51,    11] loss: 0.577
[52,    11] loss: 0.576
[53,    11] loss: 0.571
[54,    11] loss: 0.569
[55,    11] loss: 0.565
[56,    11] loss: 0.566
[57,    11] loss: 0.569
[58,    11] loss: 0.579
[59,    11] loss: 0.589
[60,    11] loss: 0.576
[61,    11] loss: 0.581
[62,    11] loss: 0.570
[63,    11] loss: 0.564
[64,    11] loss: 0.554
[65,    11] loss: 0.571
[66,    11] loss: 0.571
[67,    11] loss: 0.572
[68,    11] loss: 0.591
[69,    11] loss: 0.573
[70,    11] loss: 0.562
[71,    11] loss: 0.567
[72,    11] loss: 0.572
[73,    11] loss: 0.567
[74,    11] loss: 0.563
[75,    11] loss: 0.599
[76,    11] loss: 0.568
[77,    11] loss: 0.565
[78,    11] loss: 0.583
[79,    11] loss: 0.564
[80,    11] loss: 0.575
[81,    11] loss: 0.578
[82,    11] loss: 0.567
[83,    11] loss: 0.557
[84,    11] loss: 0.561
[85,    11] loss: 0.567
[86,    11] loss: 0.573
[87,    11] loss: 0.578
[88,    11] loss: 0.565
[89,    11] loss: 0.566
[90,    11] loss: 0.580
[91,    11] loss: 0.569
[92,    11] loss: 0.586
[93,    11] loss: 0.578
[94,    11] loss: 0.580
[95,    11] loss: 0.575
[96,    11] loss: 0.560
[97,    11] loss: 0.571
[98,    11] loss: 0.571
[99,    11] loss: 0.557
[100,    11] loss: 0.552
[101,    11] loss: 0.561
[102,    11] loss: 0.563
[103,    11] loss: 0.568
[104,    11] loss: 0.561
[105,    11] loss: 0.555
[106,    11] loss: 0.547
[107,    11] loss: 0.577
[108,    11] loss: 0.576
[109,    11] loss: 0.575
[110,    11] loss: 0.558
[111,    11] loss: 0.558
[112,    11] loss: 0.561
[113,    11] loss: 0.558
[114,    11] loss: 0.569
[115,    11] loss: 0.566
[116,    11] loss: 0.569
[117,    11] loss: 0.572
[118,    11] loss: 0.562
[119,    11] loss: 0.591
[120,    11] loss: 0.583
[121,    11] loss: 0.580
[122,    11] loss: 0.575
[123,    11] loss: 0.573
[124,    11] loss: 0.567
[125,    11] loss: 0.561
[126,    11] loss: 0.558
[127,    11] loss: 0.554
[128,    11] loss: 0.562
[129,    11] loss: 0.567
[130,    11] loss: 0.563
[131,    11] loss: 0.574
[132,    11] loss: 0.572
[133,    11] loss: 0.567
[134,    11] loss: 0.554
[135,    11] loss: 0.568
[136,    11] loss: 0.555
[137,    11] loss: 0.564
[138,    11] loss: 0.556
[139,    11] loss: 0.568
[140,    11] loss: 0.567
[141,    11] loss: 0.561
[142,    11] loss: 0.562
[143,    11] loss: 0.571
[144,    11] loss: 0.553
[145,    11] loss: 0.575
[146,    11] loss: 0.595
[147,    11] loss: 0.563
[148,    11] loss: 0.565
[149,    11] loss: 0.561
[150,    11] loss: 0.564
[151,    11] loss: 0.571
[152,    11] loss: 0.586
[153,    11] loss: 0.565
[154,    11] loss: 0.573
[155,    11] loss: 0.564
[156,    11] loss: 0.581
[157,    11] loss: 0.568
[158,    11] loss: 0.573
[159,    11] loss: 0.588
[160,    11] loss: 0.571
[161,    11] loss: 0.566
[162,    11] loss: 0.559
[163,    11] loss: 0.567
[164,    11] loss: 0.565
[165,    11] loss: 0.571
Early stopping applied (best metric=0.37860098481178284)
Finished Training
Total time taken: 67.00624060630798
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.691
[4,    11] loss: 0.691
[5,    11] loss: 0.691
[6,    11] loss: 0.690
[7,    11] loss: 0.691
[8,    11] loss: 0.690
[9,    11] loss: 0.688
[10,    11] loss: 0.687
[11,    11] loss: 0.689
[12,    11] loss: 0.688
[13,    11] loss: 0.689
[14,    11] loss: 0.685
[15,    11] loss: 0.688
[16,    11] loss: 0.688
[17,    11] loss: 0.688
[18,    11] loss: 0.687
[19,    11] loss: 0.673
[20,    11] loss: 0.649
[21,    11] loss: 0.626
[22,    11] loss: 0.637
[23,    11] loss: 0.622
[24,    11] loss: 0.609
[25,    11] loss: 0.601
[26,    11] loss: 0.586
[27,    11] loss: 0.602
[28,    11] loss: 0.599
[29,    11] loss: 0.605
[30,    11] loss: 0.587
[31,    11] loss: 0.579
[32,    11] loss: 0.579
[33,    11] loss: 0.590
[34,    11] loss: 0.581
[35,    11] loss: 0.585
[36,    11] loss: 0.598
[37,    11] loss: 0.594
[38,    11] loss: 0.572
[39,    11] loss: 0.578
[40,    11] loss: 0.572
[41,    11] loss: 0.578
[42,    11] loss: 0.579
[43,    11] loss: 0.573
[44,    11] loss: 0.582
[45,    11] loss: 0.575
[46,    11] loss: 0.580
[47,    11] loss: 0.572
[48,    11] loss: 0.574
[49,    11] loss: 0.567
[50,    11] loss: 0.566
[51,    11] loss: 0.577
[52,    11] loss: 0.565
[53,    11] loss: 0.575
[54,    11] loss: 0.560
[55,    11] loss: 0.571
[56,    11] loss: 0.571
[57,    11] loss: 0.573
[58,    11] loss: 0.564
[59,    11] loss: 0.581
[60,    11] loss: 0.570
[61,    11] loss: 0.563
[62,    11] loss: 0.567
[63,    11] loss: 0.575
[64,    11] loss: 0.560
[65,    11] loss: 0.561
[66,    11] loss: 0.568
[67,    11] loss: 0.568
[68,    11] loss: 0.558
[69,    11] loss: 0.584
[70,    11] loss: 0.577
[71,    11] loss: 0.554
[72,    11] loss: 0.552
[73,    11] loss: 0.560
[74,    11] loss: 0.552
[75,    11] loss: 0.578
[76,    11] loss: 0.574
[77,    11] loss: 0.546
[78,    11] loss: 0.566
[79,    11] loss: 0.556
[80,    11] loss: 0.555
[81,    11] loss: 0.553
[82,    11] loss: 0.561
[83,    11] loss: 0.567
[84,    11] loss: 0.574
[85,    11] loss: 0.568
[86,    11] loss: 0.565
[87,    11] loss: 0.560
[88,    11] loss: 0.560
[89,    11] loss: 0.577
[90,    11] loss: 0.571
[91,    11] loss: 0.567
[92,    11] loss: 0.566
[93,    11] loss: 0.569
[94,    11] loss: 0.563
[95,    11] loss: 0.554
[96,    11] loss: 0.562
[97,    11] loss: 0.565
[98,    11] loss: 0.572
[99,    11] loss: 0.562
[100,    11] loss: 0.579
[101,    11] loss: 0.562
[102,    11] loss: 0.567
[103,    11] loss: 0.546
[104,    11] loss: 0.561
[105,    11] loss: 0.551
[106,    11] loss: 0.553
[107,    11] loss: 0.563
[108,    11] loss: 0.555
[109,    11] loss: 0.554
[110,    11] loss: 0.557
[111,    11] loss: 0.561
[112,    11] loss: 0.564
[113,    11] loss: 0.561
[114,    11] loss: 0.563
[115,    11] loss: 0.570
[116,    11] loss: 0.563
[117,    11] loss: 0.574
[118,    11] loss: 0.568
[119,    11] loss: 0.566
[120,    11] loss: 0.565
[121,    11] loss: 0.557
[122,    11] loss: 0.560
[123,    11] loss: 0.580
[124,    11] loss: 0.558
[125,    11] loss: 0.564
[126,    11] loss: 0.570
[127,    11] loss: 0.575
[128,    11] loss: 0.558
[129,    11] loss: 0.556
[130,    11] loss: 0.557
[131,    11] loss: 0.554
[132,    11] loss: 0.558
[133,    11] loss: 0.554
[134,    11] loss: 0.557
[135,    11] loss: 0.560
[136,    11] loss: 0.557
[137,    11] loss: 0.555
[138,    11] loss: 0.541
[139,    11] loss: 0.556
[140,    11] loss: 0.551
[141,    11] loss: 0.553
[142,    11] loss: 0.549
[143,    11] loss: 0.574
[144,    11] loss: 0.567
[145,    11] loss: 0.552
[146,    11] loss: 0.566
[147,    11] loss: 0.564
[148,    11] loss: 0.560
[149,    11] loss: 0.570
[150,    11] loss: 0.564
[151,    11] loss: 0.551
[152,    11] loss: 0.562
[153,    11] loss: 0.557
[154,    11] loss: 0.576
[155,    11] loss: 0.564
[156,    11] loss: 0.557
[157,    11] loss: 0.560
[158,    11] loss: 0.550
[159,    11] loss: 0.567
[160,    11] loss: 0.561
[161,    11] loss: 0.560
[162,    11] loss: 0.552
[163,    11] loss: 0.562
[164,    11] loss: 0.572
[165,    11] loss: 0.562
[166,    11] loss: 0.556
[167,    11] loss: 0.555
[168,    11] loss: 0.551
[169,    11] loss: 0.559
[170,    11] loss: 0.556
[171,    11] loss: 0.572
[172,    11] loss: 0.550
[173,    11] loss: 0.548
[174,    11] loss: 0.558
[175,    11] loss: 0.555
[176,    11] loss: 0.574
[177,    11] loss: 0.578
[178,    11] loss: 0.566
[179,    11] loss: 0.556
[180,    11] loss: 0.556
[181,    11] loss: 0.576
[182,    11] loss: 0.556
[183,    11] loss: 0.558
Early stopping applied (best metric=0.3787103295326233)
Finished Training
Total time taken: 76.77440357208252
[1,     1] loss: 0.695
[2,    11] loss: 0.692
[3,    11] loss: 0.691
[4,    11] loss: 0.691
[5,    11] loss: 0.689
[6,    11] loss: 0.689
[7,    11] loss: 0.688
[8,    11] loss: 0.688
[9,    11] loss: 0.687
[10,    11] loss: 0.688
[11,    11] loss: 0.687
[12,    11] loss: 0.688
[13,    11] loss: 0.686
[14,    11] loss: 0.686
[15,    11] loss: 0.687
[16,    11] loss: 0.679
[17,    11] loss: 0.674
[18,    11] loss: 0.658
[19,    11] loss: 0.635
[20,    11] loss: 0.619
[21,    11] loss: 0.619
[22,    11] loss: 0.612
[23,    11] loss: 0.611
[24,    11] loss: 0.601
[25,    11] loss: 0.598
[26,    11] loss: 0.586
[27,    11] loss: 0.585
[28,    11] loss: 0.584
[29,    11] loss: 0.581
[30,    11] loss: 0.602
[31,    11] loss: 0.588
[32,    11] loss: 0.584
[33,    11] loss: 0.580
[34,    11] loss: 0.580
[35,    11] loss: 0.573
[36,    11] loss: 0.574
[37,    11] loss: 0.583
[38,    11] loss: 0.581
[39,    11] loss: 0.571
[40,    11] loss: 0.587
[41,    11] loss: 0.567
[42,    11] loss: 0.577
[43,    11] loss: 0.571
[44,    11] loss: 0.587
[45,    11] loss: 0.571
[46,    11] loss: 0.575
[47,    11] loss: 0.566
[48,    11] loss: 0.564
[49,    11] loss: 0.565
[50,    11] loss: 0.570
[51,    11] loss: 0.571
[52,    11] loss: 0.583
[53,    11] loss: 0.569
[54,    11] loss: 0.569
[55,    11] loss: 0.566
[56,    11] loss: 0.567
[57,    11] loss: 0.567
[58,    11] loss: 0.557
[59,    11] loss: 0.566
[60,    11] loss: 0.572
[61,    11] loss: 0.563
[62,    11] loss: 0.576
[63,    11] loss: 0.583
[64,    11] loss: 0.573
[65,    11] loss: 0.565
[66,    11] loss: 0.574
[67,    11] loss: 0.569
[68,    11] loss: 0.555
[69,    11] loss: 0.567
[70,    11] loss: 0.565
[71,    11] loss: 0.557
[72,    11] loss: 0.560
[73,    11] loss: 0.570
[74,    11] loss: 0.576
[75,    11] loss: 0.567
[76,    11] loss: 0.575
[77,    11] loss: 0.573
[78,    11] loss: 0.575
[79,    11] loss: 0.570
[80,    11] loss: 0.569
[81,    11] loss: 0.564
[82,    11] loss: 0.563
[83,    11] loss: 0.596
[84,    11] loss: 0.565
[85,    11] loss: 0.560
[86,    11] loss: 0.561
[87,    11] loss: 0.564
[88,    11] loss: 0.578
[89,    11] loss: 0.570
[90,    11] loss: 0.562
[91,    11] loss: 0.575
[92,    11] loss: 0.571
[93,    11] loss: 0.568
[94,    11] loss: 0.562
[95,    11] loss: 0.562
[96,    11] loss: 0.568
[97,    11] loss: 0.569
[98,    11] loss: 0.573
[99,    11] loss: 0.569
[100,    11] loss: 0.557
[101,    11] loss: 0.569
[102,    11] loss: 0.564
[103,    11] loss: 0.564
[104,    11] loss: 0.574
[105,    11] loss: 0.566
[106,    11] loss: 0.561
[107,    11] loss: 0.603
[108,    11] loss: 0.587
[109,    11] loss: 0.563
[110,    11] loss: 0.555
[111,    11] loss: 0.570
[112,    11] loss: 0.565
[113,    11] loss: 0.574
[114,    11] loss: 0.558
[115,    11] loss: 0.579
[116,    11] loss: 0.559
[117,    11] loss: 0.557
[118,    11] loss: 0.576
[119,    11] loss: 0.570
[120,    11] loss: 0.572
[121,    11] loss: 0.569
[122,    11] loss: 0.564
[123,    11] loss: 0.565
[124,    11] loss: 0.562
[125,    11] loss: 0.563
[126,    11] loss: 0.567
[127,    11] loss: 0.557
[128,    11] loss: 0.552
[129,    11] loss: 0.557
[130,    11] loss: 0.570
[131,    11] loss: 0.566
[132,    11] loss: 0.567
[133,    11] loss: 0.567
[134,    11] loss: 0.561
[135,    11] loss: 0.546
[136,    11] loss: 0.561
[137,    11] loss: 0.560
[138,    11] loss: 0.564
[139,    11] loss: 0.578
[140,    11] loss: 0.570
Early stopping applied (best metric=0.3817974328994751)
Finished Training
Total time taken: 61.36618089675903
{'Sumoylation Validation Accuracy': 0.66720607229876, 'Sumoylation Validation Sensitivity': 0.7682688466586772, 'Sumoylation Validation Specificity': 0.6510300459267793, 'Sumoylation Validation Precision': 0.2606746762619367, 'Sumoylation AUC ROC': 0.7969920285402349, 'Sumoylation AUC PR': 0.4981843079232649, 'Sumoylation MCC': 0.294524509452388, 'Sumoylation F1': 0.3891366867928698, 'Validation Loss (Sumoylation)': 0.3747238993644714, 'Validation Loss (total)': 0.3747238993644714, 'TimeToTrain': 69.00363731384277}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005668013865614811,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3651045811,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 3.156997295017236}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.691
[4,    11] loss: 0.692
[5,    11] loss: 0.691
[6,    11] loss: 0.691
[7,    11] loss: 0.690
[8,    11] loss: 0.689
[9,    11] loss: 0.689
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 7.804167792151324e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2014260020,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 5.9196493062404345}
[1,     1] loss: 0.697
[2,    11] loss: 0.694
[3,    11] loss: 0.694
[4,    11] loss: 0.694
[5,    11] loss: 0.694
[6,    11] loss: 0.693
[7,    11] loss: 0.694
[8,    11] loss: 0.695
[9,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022311775776544364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1638806866,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.540696019367658}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026661281403669826,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1769793211,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 7.8905825892374}
[1,     1] loss: 0.695
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.690
[9,    11] loss: 0.680
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008789935574426089,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2588887725,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 1.3710251450526818}
[1,     1] loss: 0.699
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.691
[5,    11] loss: 0.692
[6,    11] loss: 0.690
[7,    11] loss: 0.689
[8,    11] loss: 0.688
[9,    11] loss: 0.688
[10,    11] loss: 0.689
[11,    11] loss: 0.688
[12,    11] loss: 0.689
[13,    11] loss: 0.689
[14,    11] loss: 0.690
[15,    11] loss: 0.689
[16,    11] loss: 0.686
[17,    11] loss: 0.690
[18,    11] loss: 0.690
[19,    11] loss: 0.689
[20,    11] loss: 0.688
[21,    11] loss: 0.683
[22,    11] loss: 0.689
[23,    11] loss: 0.688
[24,    11] loss: 0.686
[25,    11] loss: 0.688
[26,    11] loss: 0.688
[27,    11] loss: 0.688
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004412711753485994,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3905532888,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 4.801388456830663}
[1,     1] loss: 0.697
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002793830290599675,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 4026124898,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 8.150406231576588}
[1,     1] loss: 0.698
[2,    11] loss: 0.692
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035560138157985136,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1534732994,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 18.96185571530088}
[1,     1] loss: 0.697
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007602021672926501,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 819635671,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 0.4229778251385594}
[1,     1] loss: 0.696
[2,    11] loss: 0.691
[3,    11] loss: 0.691
[4,    11] loss: 0.690
[5,    11] loss: 0.689
[6,    11] loss: 0.689
[7,    11] loss: 0.688
[8,    11] loss: 0.688
[9,    11] loss: 0.688
[10,    11] loss: 0.688
[11,    11] loss: 0.688
[12,    11] loss: 0.687
[13,    11] loss: 0.687
[14,    11] loss: 0.687
[15,    11] loss: 0.687
[16,    11] loss: 0.687
[17,    11] loss: 0.687
[18,    11] loss: 0.688
[19,    11] loss: 0.686
[20,    11] loss: 0.688
[21,    11] loss: 0.690
[22,    11] loss: 0.689
[23,    11] loss: 0.687
[24,    11] loss: 0.687
[25,    11] loss: 0.687
[26,    11] loss: 0.687
[27,    11] loss: 0.687
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033633905727779487,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3983210726,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 24.841743433125036}
[1,     1] loss: 0.693
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0066736510924412995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1481345088,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 24.494267793857233}
[1,     1] loss: 0.692
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009624717492868235,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3033269928,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 16.120874862095203}
[1,     1] loss: 0.692
[2,    11] loss: 0.693
[3,    11] loss: 0.692
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005356210138952325,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 4126444398,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 1.1283999973396157}
[1,     1] loss: 0.696
[2,    11] loss: 0.692
[3,    11] loss: 0.691
[4,    11] loss: 0.691
[5,    11] loss: 0.690
[6,    11] loss: 0.689
[7,    11] loss: 0.688
[8,    11] loss: 0.687
[9,    11] loss: 0.687
[10,    11] loss: 0.687
[11,    11] loss: 0.685
[12,    11] loss: 0.688
[13,    11] loss: 0.684
[14,    11] loss: 0.687
[15,    11] loss: 0.684
[16,    11] loss: 0.687
[17,    11] loss: 0.684
[18,    11] loss: 0.686
[19,    11] loss: 0.685
[20,    11] loss: 0.683
[21,    11] loss: 0.680
[22,    11] loss: 0.682
[23,    11] loss: 0.673
[24,    11] loss: 0.657
[25,    11] loss: 0.635
[26,    11] loss: 0.633
[27,    11] loss: 0.618
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002692867687156472,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 88556358,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 22.98490259486739}
[1,     1] loss: 0.696
[2,    11] loss: 0.692
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00999832235385167,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1868083186,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 8.804636609645422}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005703936356552711,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 723590425,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 4.771782822937093}
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008024531029376126,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3774405001,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 5.498029493024374}
[1,     1] loss: 0.692
[2,    11] loss: 0.692
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.691
[8,    11] loss: 0.690
[9,    11] loss: 0.690
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00797307176838101,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2201312216,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 0.348004192653649}
[1,     1] loss: 0.696
[2,    11] loss: 0.693
[3,    11] loss: 0.691
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003039004275195698,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 2510411720,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 1.1440691752378473}
[1,     1] loss: 0.697
[2,    11] loss: 0.692
[3,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007262049963109896,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 1176765344,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 24.10101709257846}
[1,     1] loss: 0.695
[2,    11] loss: 0.693
[3,    11] loss: 0.693
[4,    11] loss: 0.693
[5,    11] loss: 0.693
[6,    11] loss: 0.693
[7,    11] loss: 0.693
[8,    11] loss: 0.693
[9,    11] loss: 0.693
[10,    11] loss: 0.693
[11,    11] loss: 0.693
[12,    11] loss: 0.693
[13,    11] loss: 0.693
[14,    11] loss: 0.693
[15,    11] loss: 0.693
[16,    11] loss: 0.693
[17,    11] loss: 0.693
[18,    11] loss: 0.693
[19,    11] loss: 0.693
[20,    11] loss: 0.693
[21,    11] loss: 0.693
[22,    11] loss: 0.693
[23,    11] loss: 0.693
[24,    11] loss: 0.693
[25,    11] loss: 0.693
[26,    11] loss: 0.693
[27,    11] loss: 0.693
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'hydroxyretest - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'SeperateTuningLRandWD': False,
 'SpecieFeatureHoldout': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Sumoylation'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00816744008561399,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'onlyPredictHumans': False,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'predictSpecies': False,
 'random_state': 3929673963,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useSpecieFeature': True,
 'weight_decay': 5.731015065266407}
[1,     1] loss: 0.699
[2,    11] loss: 0.692
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.691
[6,    11] loss: 0.691
[7,    11] loss: 0.690
[8,    11] loss: 0.684
[9,    11] loss: 0.676
[10,    11] loss: 0.682
[11,    11] loss: 0.666
[12,    11] loss: 0.649
[13,    11] loss: 0.630
[14,    11] loss: 0.635
[15,    11] loss: 0.653
[16,    11] loss: 0.657
[17,    11] loss: 0.632
[18,    11] loss: 0.631
[19,    11] loss: 0.629
[20,    11] loss: 0.642
[21,    11] loss: 0.630
[22,    11] loss: 0.629
[23,    11] loss: 0.637
[24,    11] loss: 0.625
[25,    11] loss: 0.624
[26,    11] loss: 0.646
[27,    11] loss: 0.643
[28,    11] loss: 0.634
[29,    11] loss: 0.659
[30,    11] loss: 0.627
[31,    11] loss: 0.638
[32,    11] loss: 0.623
[33,    11] loss: 0.652
[34,    11] loss: 0.628
[35,    11] loss: 0.635
[36,    11] loss: 0.639
[37,    11] loss: 0.640
[38,    11] loss: 0.624
[39,    11] loss: 0.635
[40,    11] loss: 0.635
[41,    11] loss: 0.632
[42,    11] loss: 0.631
[43,    11] loss: 0.643
[44,    11] loss: 0.638
[45,    11] loss: 0.635
[46,    11] loss: 0.637
[47,    11] loss: 0.635
[48,    11] loss: 0.639
[49,    11] loss: 0.641
[50,    11] loss: 0.646
[51,    11] loss: 0.641
[52,    11] loss: 0.636
[53,    11] loss: 0.649
[54,    11] loss: 0.641
[55,    11] loss: 0.649
[56,    11] loss: 0.650
[57,    11] loss: 0.662
[58,    11] loss: 0.644
[59,    11] loss: 0.635
[60,    11] loss: 0.651
[61,    11] loss: 0.650
[62,    11] loss: 0.652
[63,    11] loss: 0.642
[64,    11] loss: 0.694
[65,    11] loss: 0.693
[66,    11] loss: 0.693
[67,    11] loss: 0.693
Early stopping applied (best metric=0.4163495600223541)
Finished Training
Total time taken: 28.550387382507324
[1,     1] loss: 0.694
[2,    11] loss: 0.693
[3,    11] loss: 0.692
[4,    11] loss: 0.692
[5,    11] loss: 0.692
[6,    11] loss: 0.692
[7,    11] loss: 0.692
[8,    11] loss: 0.692
[9,    11] loss: 0.692
[10,    11] loss: 0.692
[11,    11] loss: 0.691
[12,    11] loss: 0.690
[13,    11] loss: 0.682
[14,    11] loss: 0.694
[15,    11] loss: 0.688
[16,    11] loss: 0.687
[17,    11] loss: 0.685
[18,    11] loss: 0.669
[19,    11] loss: 0.663
[20,    11] loss: 0.648
[21,    11] loss: 0.631
[22,    11] loss: 0.677
[23,    11] loss: 0.680
[24,    11] loss: 0.663
[25,    11] loss: 0.655
[26,    11] loss: 0.644
[27,    11] loss: 0.661
[28,    11] loss: 0.642
[29,    11] loss: 0.635
[30,    11] loss: 0.657
[31,    11] loss: 0.666
[32,    11] loss: 0.649
[33,    11] loss: 0.641
[34,    11] loss: 0.649
[35,    11] loss: 0.630
[36,    11] loss: 0.641
[37,    11] loss: 0.636
[38,    11] loss: 0.644
[39,    11] loss: 0.651
[40,    11] loss: 0.669
[41,    11] loss: 0.645
[42,    11] loss: 0.646
[43,    11] loss: 0.637
[44,    11] loss: 0.646
[45,    11] loss: 0.642
[46,    11] loss: 0.637
[47,    11] loss: 0.631
[48,    11] loss: 0.643
[49,    11] loss: 0.670
[50,    11] loss: 0.658
[51,    11] loss: 0.640
[52,    11] loss: 0.648
[53,    11] loss: 0.675
[54,    11] loss: 0.673
[55,    11] loss: 0.644
[56,    11] loss: 0.644
[57,    11] loss: 0.648
[58,    11] loss: 0.649
[59,    11] loss: 0.652
[60,    11] loss: 0.654
[61,    11] loss: 0.648
[62,    11] loss: 0.640
[63,    11] loss: 0.636
[64,    11] loss: 0.648
